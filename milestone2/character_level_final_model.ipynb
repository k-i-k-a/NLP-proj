{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ca88218",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:11:32.415411Z",
     "iopub.status.busy": "2025-04-20T11:11:32.415177Z",
     "iopub.status.idle": "2025-04-20T11:11:47.109394Z",
     "shell.execute_reply": "2025-04-20T11:11:47.108729Z"
    },
    "papermill": {
     "duration": 14.699706,
     "end_time": "2025-04-20T11:11:47.111021",
     "exception": false,
     "start_time": "2025-04-20T11:11:32.411315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 11:11:34.046021: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745147494.268084      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745147494.331886      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Concatenate\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d202ad6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:11:47.117103Z",
     "iopub.status.busy": "2025-04-20T11:11:47.116654Z",
     "iopub.status.idle": "2025-04-20T11:11:49.178720Z",
     "shell.execute_reply": "2025-04-20T11:11:49.177757Z"
    },
    "papermill": {
     "duration": 2.066246,
     "end_time": "2025-04-20T11:11:49.180099",
     "exception": false,
     "start_time": "2025-04-20T11:11:47.113853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading SQuAD v1.1 dataset...\n",
      "Download complete!\n",
      "Data split completed.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib.request\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\"\n",
    "filename = \"train-v1.1.json\"\n",
    "\n",
    "if not os.path.exists(filename):\n",
    "    print(\"Downloading SQuAD v1.1 dataset...\")\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "    print(\"Download complete!\")\n",
    "else:\n",
    "    print(\"SQuAD dataset already downloaded.\")\n",
    "\n",
    "with open(\"train-v1.1.json\", \"r\") as f:\n",
    "    squad_data = json.load(f)\n",
    "\n",
    "context_to_qa = {}\n",
    "\n",
    "# Group one QA per unique context\n",
    "for article in squad_data['data']:\n",
    "    for paragraph in article['paragraphs']:\n",
    "        context = paragraph['context']\n",
    "        if context not in context_to_qa:\n",
    "            for qa in paragraph['qas']:\n",
    "                if qa['answers']:\n",
    "                    context_to_qa[context] = (qa['question'], f\"<{qa['answers'][0]['text']}>\")\n",
    "                    break \n",
    "\n",
    "unique_contexts = list(context_to_qa.items())\n",
    "random.shuffle(unique_contexts)\n",
    "\n",
    "sampled_contexts = unique_contexts[:20000]\n",
    "\n",
    "contexts = [c for c, _ in sampled_contexts]\n",
    "questions = [q for _, (q, _) in sampled_contexts]\n",
    "answers = [a for _, (_, a) in sampled_contexts]\n",
    "\n",
    "contexts_train, contexts_temp, questions_train, questions_temp, answers_train, answers_temp = train_test_split(\n",
    "    contexts, questions, answers, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "contexts_val, contexts_test, questions_val, questions_test, answers_val, answers_test = train_test_split(\n",
    "    contexts_temp, questions_temp, answers_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "with open(\"train_data.json\", \"w\") as f:\n",
    "    json.dump({\"contexts\": contexts_train, \"questions\": questions_train, \"answers\": answers_train}, f)\n",
    "\n",
    "# Save validation set\n",
    "with open(\"val_data.json\", \"w\") as f:\n",
    "    json.dump({\"contexts\": contexts_val, \"questions\": questions_val, \"answers\": answers_val}, f)\n",
    "\n",
    "# Save testing set\n",
    "with open(\"test_data.json\", \"w\") as f:\n",
    "    json.dump({\"contexts\": contexts_test, \"questions\": questions_test, \"answers\": answers_test}, f)\n",
    "\n",
    "print(\"Data split completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fb4d2c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:11:49.186075Z",
     "iopub.status.busy": "2025-04-20T11:11:49.185619Z",
     "iopub.status.idle": "2025-04-20T11:11:52.957343Z",
     "shell.execute_reply": "2025-04-20T11:11:52.956728Z"
    },
    "papermill": {
     "duration": 3.776186,
     "end_time": "2025-04-20T11:11:52.958812",
     "exception": false,
     "start_time": "2025-04-20T11:11:49.182626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use char-level tokenizers\n",
    "context_tokenizer = Tokenizer( char_level=True,lower=False)\n",
    "question_tokenizer = Tokenizer(char_level=True,lower=False)\n",
    "answer_tokenizer = Tokenizer(char_level=True,lower=False, filters='')\n",
    "\n",
    "context_tokenizer.fit_on_texts(contexts_train)\n",
    "question_tokenizer.fit_on_texts(questions_train)\n",
    "answer_tokenizer.fit_on_texts(answers_train)\n",
    "\n",
    "context_sequences = context_tokenizer.texts_to_sequences(contexts_train)\n",
    "question_sequences = question_tokenizer.texts_to_sequences(questions_train)\n",
    "answer_sequences = answer_tokenizer.texts_to_sequences(answers_train)\n",
    "\n",
    "max_context_len = max([len(seq) for seq in context_sequences])\n",
    "max_question_len = max([len(seq) for seq in question_sequences])\n",
    "max_answer_len = max([len(seq) for seq in answer_sequences])\n",
    "\n",
    "context_padded = pad_sequences(context_sequences, maxlen=max_context_len, padding='post')\n",
    "question_padded = pad_sequences(question_sequences, maxlen=max_question_len, padding='post')\n",
    "answer_padded = pad_sequences(answer_sequences, maxlen=max_answer_len, padding='post')\n",
    "\n",
    "decoder_input_data = answer_padded[:, :-1]\n",
    "decoder_target_data = np.expand_dims(answer_padded[:, 1:], -1)\n",
    "\n",
    "context_sequences_val = context_tokenizer.texts_to_sequences(contexts_val)\n",
    "question_sequences_val = question_tokenizer.texts_to_sequences(questions_val)\n",
    "answer_sequences_val = answer_tokenizer.texts_to_sequences(answers_val)\n",
    "\n",
    "context_padded_val = pad_sequences(context_sequences_val, maxlen=max_context_len, padding='post')\n",
    "question_padded_val = pad_sequences(question_sequences_val, maxlen=max_question_len, padding='post')\n",
    "answer_padded_val = pad_sequences(answer_sequences_val, maxlen=max_answer_len, padding='post')\n",
    "\n",
    "decoder_input_data_val = answer_padded_val[:, :-1]\n",
    "decoder_target_data_val = np.expand_dims(answer_padded_val[:, 1:], -1)\n",
    "\n",
    "context_sequences_test = context_tokenizer.texts_to_sequences(contexts_test)\n",
    "question_sequences_test = question_tokenizer.texts_to_sequences(questions_test)\n",
    "answer_sequences_test = answer_tokenizer.texts_to_sequences(answers_test)\n",
    "\n",
    "context_padded_test = pad_sequences(context_sequences_test, maxlen=max_context_len, padding='post')\n",
    "question_padded_test = pad_sequences(question_sequences_test, maxlen=max_question_len, padding='post')\n",
    "answer_padded_test = pad_sequences(answer_sequences_test, maxlen=max_answer_len, padding='post')\n",
    "\n",
    "decoder_input_data_test = answer_padded_test[:, :-1]\n",
    "decoder_target_data_test = np.expand_dims(answer_padded_test[:, 1:], -1)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Save tokenizers\n",
    "with open('context_tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(context_tokenizer, f)\n",
    "\n",
    "with open('question_tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(question_tokenizer, f)\n",
    "\n",
    "with open('answer_tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(answer_tokenizer, f)\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "max_lengths = {\n",
    "    'max_context_len': max_context_len,\n",
    "    'max_question_len': max_question_len,\n",
    "    'max_answer_len': max_answer_len\n",
    "}\n",
    "\n",
    "with open('max_lengths.json', 'w') as f:\n",
    "    json.dump(max_lengths, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6af4142a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:11:52.965030Z",
     "iopub.status.busy": "2025-04-20T11:11:52.964594Z",
     "iopub.status.idle": "2025-04-20T11:11:55.958692Z",
     "shell.execute_reply": "2025-04-20T11:11:55.958134Z"
    },
    "papermill": {
     "duration": 2.998655,
     "end_time": "2025-04-20T11:11:55.960089",
     "exception": false,
     "start_time": "2025-04-20T11:11:52.961434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745147514.324309      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1745147514.325031      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Assuming tokenizers are already fitted\n",
    "vocab_context = len(context_tokenizer.word_index) + 1\n",
    "vocab_question = len(question_tokenizer.word_index) + 1\n",
    "vocab_answer = len(answer_tokenizer.word_index) + 1\n",
    "\n",
    "dense_units = 256\n",
    "\n",
    "# ===== Encoder =====\n",
    "context_input = Input(shape=(context_padded.shape[1],), name=\"context_input\")\n",
    "question_input = Input(shape=(question_padded.shape[1],), name=\"question_input\")\n",
    "\n",
    "context_embedding = Embedding(vocab_context, dense_units, mask_zero=True)(context_input)\n",
    "question_embedding = Embedding(vocab_question, dense_units, mask_zero=True)(question_input)\n",
    "\n",
    "context_lstm = LSTM(dense_units, return_state=True,dropout=0.3)\n",
    "_, context_h, context_c = context_lstm(context_embedding)\n",
    "\n",
    "question_lstm = LSTM(dense_units, return_state=True,dropout=0.3)\n",
    "_, question_h, question_c = question_lstm(question_embedding)\n",
    "\n",
    "state_h = Concatenate()([context_h, question_h])  # shape: (dense_units * 2,)\n",
    "state_c = Concatenate()([context_c, question_c])\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# ===== Decoder (Training) =====\n",
    "decoder_input = Input(shape=(None,), name=\"decoder_input\")\n",
    "decoder_embedding_layer = Embedding(vocab_answer, dense_units, mask_zero=True)\n",
    "decoder_embedding = decoder_embedding_layer(decoder_input)\n",
    "\n",
    "decoder_lstm = LSTM(dense_units * 2, return_sequences=True, return_state=True,dropout=0.3)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "# ✅ Shared Dense layers\n",
    "decoder_dense_hidden_layer = Dense(dense_units, activation='relu', name='decoder_dense_hidden')\n",
    "decoder_dense_output_layer = Dense(vocab_answer, activation='softmax', name='decoder_dense_output')\n",
    "\n",
    "decoder_dense_hidden = decoder_dense_hidden_layer(decoder_outputs)\n",
    "decoder_dense_output = decoder_dense_output_layer(decoder_dense_hidden)\n",
    "\n",
    "# ===== Final Training Model =====\n",
    "model = Model([context_input, question_input, decoder_input], decoder_dense_output)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d46dbf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:11:55.966747Z",
     "iopub.status.busy": "2025-04-20T11:11:55.966488Z",
     "iopub.status.idle": "2025-04-20T12:36:53.752393Z",
     "shell.execute_reply": "2025-04-20T12:36:53.751601Z"
    },
    "papermill": {
     "duration": 5097.790955,
     "end_time": "2025-04-20T12:36:53.753961",
     "exception": false,
     "start_time": "2025-04-20T11:11:55.963006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745147524.900663      62 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473/473 - 68s - 143ms/step - accuracy: 0.0240 - loss: 2.6212 - val_accuracy: 0.0296 - val_loss: 2.3186\n",
      "Epoch 2/80\n",
      "473/473 - 59s - 126ms/step - accuracy: 0.0319 - loss: 2.2206 - val_accuracy: 0.0342 - val_loss: 2.1330\n",
      "Epoch 3/80\n",
      "473/473 - 61s - 129ms/step - accuracy: 0.0363 - loss: 2.0519 - val_accuracy: 0.0383 - val_loss: 1.9896\n",
      "Epoch 4/80\n",
      "473/473 - 62s - 131ms/step - accuracy: 0.0400 - loss: 1.9180 - val_accuracy: 0.0414 - val_loss: 1.8808\n",
      "Epoch 5/80\n",
      "473/473 - 63s - 132ms/step - accuracy: 0.0429 - loss: 1.8065 - val_accuracy: 0.0434 - val_loss: 1.8009\n",
      "Epoch 6/80\n",
      "473/473 - 63s - 133ms/step - accuracy: 0.0451 - loss: 1.7173 - val_accuracy: 0.0443 - val_loss: 1.7578\n",
      "Epoch 7/80\n",
      "473/473 - 63s - 134ms/step - accuracy: 0.0468 - loss: 1.6447 - val_accuracy: 0.0455 - val_loss: 1.7134\n",
      "Epoch 8/80\n",
      "473/473 - 63s - 134ms/step - accuracy: 0.0482 - loss: 1.5811 - val_accuracy: 0.0461 - val_loss: 1.6942\n",
      "Epoch 9/80\n",
      "473/473 - 64s - 134ms/step - accuracy: 0.0494 - loss: 1.5272 - val_accuracy: 0.0467 - val_loss: 1.6720\n",
      "Epoch 10/80\n",
      "473/473 - 64s - 134ms/step - accuracy: 0.0506 - loss: 1.4782 - val_accuracy: 0.0470 - val_loss: 1.6615\n",
      "Epoch 11/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0515 - loss: 1.4339 - val_accuracy: 0.0471 - val_loss: 1.6622\n",
      "Epoch 12/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0525 - loss: 1.3931 - val_accuracy: 0.0472 - val_loss: 1.6669\n",
      "Epoch 13/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0535 - loss: 1.3509 - val_accuracy: 0.0476 - val_loss: 1.6613\n",
      "Epoch 14/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0544 - loss: 1.3112 - val_accuracy: 0.0478 - val_loss: 1.6785\n",
      "Epoch 15/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0553 - loss: 1.2731 - val_accuracy: 0.0479 - val_loss: 1.6893\n",
      "Epoch 16/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0562 - loss: 1.2339 - val_accuracy: 0.0475 - val_loss: 1.7120\n",
      "Epoch 17/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0572 - loss: 1.1958 - val_accuracy: 0.0475 - val_loss: 1.7317\n",
      "Epoch 18/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0582 - loss: 1.1579 - val_accuracy: 0.0474 - val_loss: 1.7573\n",
      "Epoch 19/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0591 - loss: 1.1181 - val_accuracy: 0.0473 - val_loss: 1.7872\n",
      "Epoch 20/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0601 - loss: 1.0816 - val_accuracy: 0.0473 - val_loss: 1.8198\n",
      "Epoch 21/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0611 - loss: 1.0430 - val_accuracy: 0.0472 - val_loss: 1.8583\n",
      "Epoch 22/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0620 - loss: 1.0043 - val_accuracy: 0.0471 - val_loss: 1.9000\n",
      "Epoch 23/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0628 - loss: 0.9704 - val_accuracy: 0.0468 - val_loss: 1.9446\n",
      "Epoch 24/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0638 - loss: 0.9333 - val_accuracy: 0.0467 - val_loss: 1.9884\n",
      "Epoch 25/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0646 - loss: 0.9024 - val_accuracy: 0.0464 - val_loss: 2.0415\n",
      "Epoch 26/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0657 - loss: 0.8646 - val_accuracy: 0.0463 - val_loss: 2.0821\n",
      "Epoch 27/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0666 - loss: 0.8316 - val_accuracy: 0.0462 - val_loss: 2.1521\n",
      "Epoch 28/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0673 - loss: 0.8024 - val_accuracy: 0.0460 - val_loss: 2.1965\n",
      "Epoch 29/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0681 - loss: 0.7739 - val_accuracy: 0.0457 - val_loss: 2.2478\n",
      "Epoch 30/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0689 - loss: 0.7446 - val_accuracy: 0.0460 - val_loss: 2.2885\n",
      "Epoch 31/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0696 - loss: 0.7185 - val_accuracy: 0.0459 - val_loss: 2.3399\n",
      "Epoch 32/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0702 - loss: 0.6934 - val_accuracy: 0.0456 - val_loss: 2.3908\n",
      "Epoch 33/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0710 - loss: 0.6666 - val_accuracy: 0.0455 - val_loss: 2.4660\n",
      "Epoch 34/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0715 - loss: 0.6450 - val_accuracy: 0.0452 - val_loss: 2.5251\n",
      "Epoch 35/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0721 - loss: 0.6238 - val_accuracy: 0.0452 - val_loss: 2.5707\n",
      "Epoch 36/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0727 - loss: 0.6017 - val_accuracy: 0.0452 - val_loss: 2.6400\n",
      "Epoch 37/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0732 - loss: 0.5838 - val_accuracy: 0.0449 - val_loss: 2.6825\n",
      "Epoch 38/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0737 - loss: 0.5637 - val_accuracy: 0.0454 - val_loss: 2.7313\n",
      "Epoch 39/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0743 - loss: 0.5419 - val_accuracy: 0.0448 - val_loss: 2.7999\n",
      "Epoch 40/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0747 - loss: 0.5289 - val_accuracy: 0.0447 - val_loss: 2.8643\n",
      "Epoch 41/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0751 - loss: 0.5133 - val_accuracy: 0.0449 - val_loss: 2.9239\n",
      "Epoch 42/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0755 - loss: 0.4970 - val_accuracy: 0.0449 - val_loss: 2.9478\n",
      "Epoch 43/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0758 - loss: 0.4848 - val_accuracy: 0.0447 - val_loss: 2.9877\n",
      "Epoch 44/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0763 - loss: 0.4692 - val_accuracy: 0.0447 - val_loss: 3.0211\n",
      "Epoch 45/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0765 - loss: 0.4615 - val_accuracy: 0.0444 - val_loss: 3.0715\n",
      "Epoch 46/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0768 - loss: 0.4482 - val_accuracy: 0.0446 - val_loss: 3.1366\n",
      "Epoch 47/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0772 - loss: 0.4341 - val_accuracy: 0.0446 - val_loss: 3.1849\n",
      "Epoch 48/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0775 - loss: 0.4242 - val_accuracy: 0.0444 - val_loss: 3.2048\n",
      "Epoch 49/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0777 - loss: 0.4149 - val_accuracy: 0.0444 - val_loss: 3.2612\n",
      "Epoch 50/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0780 - loss: 0.4062 - val_accuracy: 0.0444 - val_loss: 3.3327\n",
      "Epoch 51/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0783 - loss: 0.3951 - val_accuracy: 0.0447 - val_loss: 3.3497\n",
      "Epoch 52/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0785 - loss: 0.3875 - val_accuracy: 0.0445 - val_loss: 3.4026\n",
      "Epoch 53/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0787 - loss: 0.3821 - val_accuracy: 0.0442 - val_loss: 3.4328\n",
      "Epoch 54/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0789 - loss: 0.3736 - val_accuracy: 0.0443 - val_loss: 3.4818\n",
      "Epoch 55/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0789 - loss: 0.3692 - val_accuracy: 0.0446 - val_loss: 3.4964\n",
      "Epoch 56/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0793 - loss: 0.3584 - val_accuracy: 0.0444 - val_loss: 3.5280\n",
      "Epoch 57/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0794 - loss: 0.3561 - val_accuracy: 0.0442 - val_loss: 3.5322\n",
      "Epoch 58/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0796 - loss: 0.3461 - val_accuracy: 0.0444 - val_loss: 3.5775\n",
      "Epoch 59/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0798 - loss: 0.3400 - val_accuracy: 0.0440 - val_loss: 3.6246\n",
      "Epoch 60/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0799 - loss: 0.3348 - val_accuracy: 0.0441 - val_loss: 3.6449\n",
      "Epoch 61/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0799 - loss: 0.3343 - val_accuracy: 0.0443 - val_loss: 3.6815\n",
      "Epoch 62/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0803 - loss: 0.3218 - val_accuracy: 0.0440 - val_loss: 3.6991\n",
      "Epoch 63/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0803 - loss: 0.3226 - val_accuracy: 0.0439 - val_loss: 3.7141\n",
      "Epoch 64/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0804 - loss: 0.3198 - val_accuracy: 0.0441 - val_loss: 3.7645\n",
      "Epoch 65/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0805 - loss: 0.3151 - val_accuracy: 0.0437 - val_loss: 3.8125\n",
      "Epoch 66/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0807 - loss: 0.3076 - val_accuracy: 0.0439 - val_loss: 3.8175\n",
      "Epoch 67/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0808 - loss: 0.3050 - val_accuracy: 0.0438 - val_loss: 3.8577\n",
      "Epoch 68/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0809 - loss: 0.2998 - val_accuracy: 0.0438 - val_loss: 3.8874\n",
      "Epoch 69/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0810 - loss: 0.2970 - val_accuracy: 0.0439 - val_loss: 3.9015\n",
      "Epoch 70/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0812 - loss: 0.2921 - val_accuracy: 0.0437 - val_loss: 3.9242\n",
      "Epoch 71/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0811 - loss: 0.2919 - val_accuracy: 0.0441 - val_loss: 3.9154\n",
      "Epoch 72/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0813 - loss: 0.2880 - val_accuracy: 0.0441 - val_loss: 3.9326\n",
      "Epoch 73/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0814 - loss: 0.2838 - val_accuracy: 0.0440 - val_loss: 3.9502\n",
      "Epoch 74/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0816 - loss: 0.2784 - val_accuracy: 0.0441 - val_loss: 3.9849\n",
      "Epoch 75/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0815 - loss: 0.2799 - val_accuracy: 0.0441 - val_loss: 3.9993\n",
      "Epoch 76/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0816 - loss: 0.2757 - val_accuracy: 0.0440 - val_loss: 4.0262\n",
      "Epoch 77/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0816 - loss: 0.2764 - val_accuracy: 0.0439 - val_loss: 4.0423\n",
      "Epoch 78/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0818 - loss: 0.2666 - val_accuracy: 0.0440 - val_loss: 4.0648\n",
      "Epoch 79/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0818 - loss: 0.2695 - val_accuracy: 0.0442 - val_loss: 4.1005\n",
      "Epoch 80/80\n",
      "473/473 - 64s - 135ms/step - accuracy: 0.0819 - loss: 0.2644 - val_accuracy: 0.0439 - val_loss: 4.0843\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [context_padded, question_padded, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=32,\n",
    "    epochs=80,\n",
    "    validation_data=([context_padded_val, question_padded_val, decoder_input_data_val], decoder_target_data_val),\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c17dde0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T12:36:53.779084Z",
     "iopub.status.busy": "2025-04-20T12:36:53.778862Z",
     "iopub.status.idle": "2025-04-20T12:36:53.848323Z",
     "shell.execute_reply": "2025-04-20T12:36:53.847580Z"
    },
    "papermill": {
     "duration": 0.0817,
     "end_time": "2025-04-20T12:36:53.849820",
     "exception": false,
     "start_time": "2025-04-20T12:36:53.768120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===== Encoder Inference Model =====\n",
    "encoder_model = Model([context_input, question_input], encoder_states)\n",
    "\n",
    "# ===== Decoder Inference Mhttps://www.kaggle.com/code/kikamagdii/fork-of-nlp-project-trialsodel =====\n",
    "decoder_inputs_inf = Input(shape=(1,), name=\"decoder_input_inf\")  # one token at a time\n",
    "decoder_state_input_h = Input(shape=(dense_units * 2,), name=\"decoder_state_input_h\")\n",
    "decoder_state_input_c = Input(shape=(dense_units * 2,), name=\"decoder_state_input_c\")\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_embedding_inf = decoder_embedding_layer(decoder_inputs_inf)\n",
    "\n",
    "decoder_outputs_inf, state_h_inf, state_c_inf = decoder_lstm(\n",
    "    decoder_embedding_inf, initial_state=decoder_states_inputs\n",
    ")\n",
    "\n",
    "decoder_hidden_inf = decoder_dense_hidden_layer(decoder_outputs_inf)\n",
    "decoder_outputs_final = decoder_dense_output_layer(decoder_hidden_inf)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs_inf, decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs_final, state_h_inf, state_c_inf]\n",
    ")\n",
    "\n",
    "# Save encoder model\n",
    "encoder_model.save(\"encoder_model.h5\")\n",
    "\n",
    "# Save decoder model\n",
    "decoder_model.save(\"decoder_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "413ebb6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T12:36:53.876042Z",
     "iopub.status.busy": "2025-04-20T12:36:53.875296Z",
     "iopub.status.idle": "2025-04-20T12:36:53.883557Z",
     "shell.execute_reply": "2025-04-20T12:36:53.882942Z"
    },
    "papermill": {
     "duration": 0.018713,
     "end_time": "2025-04-20T12:36:53.884645",
     "exception": false,
     "start_time": "2025-04-20T12:36:53.865932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_answers(input_context, input_question):\n",
    "    context_seq = context_tokenizer.texts_to_sequences([input_context])\n",
    "    context_seq = pad_sequences(context_seq, maxlen=max_context_len, padding='post')\n",
    "\n",
    "    question_seq = question_tokenizer.texts_to_sequences([input_question])\n",
    "    question_seq = pad_sequences(question_seq, maxlen=max_question_len, padding='post')\n",
    "\n",
    "    states_value = encoder_model.predict([context_seq, question_seq],verbose=0)\n",
    "\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = answer_tokenizer.word_index['<']\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value,verbose=0)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = answer_tokenizer.index_word.get(sampled_token_index, '')\n",
    "\n",
    "        if sampled_char == '>' or len(decoded_sentence) > max_answer_len:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += sampled_char\n",
    "\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f8db74b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T12:36:53.901845Z",
     "iopub.status.busy": "2025-04-20T12:36:53.901613Z",
     "iopub.status.idle": "2025-04-20T12:37:01.665952Z",
     "shell.execute_reply": "2025-04-20T12:37:01.664976Z"
    },
    "papermill": {
     "duration": 7.774354,
     "end_time": "2025-04-20T12:37:01.667210",
     "exception": false,
     "start_time": "2025-04-20T12:36:53.892856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\r\n",
      "Collecting python-Levenshtein\r\n",
      "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\r\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\r\n",
      "Collecting Levenshtein==0.27.1 (from python-Levenshtein)\r\n",
      "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\r\n",
      "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-Levenshtein)\r\n",
      "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\r\n",
      "Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\r\n",
      "Successfully installed Levenshtein-0.27.1 python-Levenshtein-0.27.1 rapidfuzz-3.13.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk python-Levenshtein\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import Levenshtein\n",
    "\n",
    "nltk.download('punkt')  # only if you need it for tokenization\n",
    "\n",
    "def evaluate_model(data_contexts, data_questions, data_answers, dataset_name=\"Test\"):\n",
    "    total_bleu = 0.0\n",
    "    total_levenshtein = 0.0\n",
    "    num_samples = len(data_contexts)\n",
    "    smooth = SmoothingFunction().method4  # for short sequences\n",
    "\n",
    "    print(f\"\\nEvaluating on {dataset_name} Set...\\n\")\n",
    "    \n",
    "    for i in range(300):\n",
    "        pred = generate_answers(data_contexts[i], data_questions[i])\n",
    "        true = data_answers[i].strip('<> ')  # Remove start/end tokens\n",
    "\n",
    "        # Tokenize for BLEU\n",
    "        reference = [list(true)]\n",
    "        candidate = list(pred)\n",
    "        bleu = sentence_bleu(reference, candidate, smoothing_function=smooth)\n",
    "        total_bleu += bleu\n",
    "\n",
    "        # Levenshtein distance\n",
    "        lev_distance = Levenshtein.distance(pred, true)\n",
    "        total_levenshtein += lev_distance\n",
    "\n",
    "        # Optional: print first few results\n",
    "        if i < 5:\n",
    "            print(f\"Context    : {data_contexts[i]}\")\n",
    "            print(f\"Question   : {data_questions[i]}\")\n",
    "            print(f\"True Answer: {true}\")\n",
    "            print(f\"Predicted  : {pred}\")\n",
    "            print(f\"BLEU Score : {bleu:.4f}\")\n",
    "            print(f\"Levenshtein Distance: {lev_distance}\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "    avg_bleu = total_bleu / num_samples\n",
    "    avg_lev = total_levenshtein / num_samples\n",
    "    print(f\"\\n{dataset_name} Set Average BLEU Score       : {avg_bleu:.4f}\")\n",
    "    print(f\"{dataset_name} Set Average Levenshtein Distance: {avg_lev:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa3e5b55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T12:37:01.686833Z",
     "iopub.status.busy": "2025-04-20T12:37:01.686023Z",
     "iopub.status.idle": "2025-04-20T12:53:54.427634Z",
     "shell.execute_reply": "2025-04-20T12:53:54.426891Z"
    },
    "papermill": {
     "duration": 1012.763017,
     "end_time": "2025-04-20T12:53:54.439638",
     "exception": false,
     "start_time": "2025-04-20T12:37:01.676621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on Test Set...\n",
      "\n",
      "Context    : North Carolina provides a large range of recreational activities, from swimming at the beach to skiing in the mountains. North Carolina offers fall colors, freshwater and saltwater fishing, hunting, birdwatching, agritourism, ATV trails, ballooning, rock climbing, biking, hiking, skiing, boating and sailing, camping, canoeing, caving (spelunking), gardens, and arboretums. North Carolina has theme parks, aquariums, museums, historic sites, lighthouses, elegant theaters, concert halls, and fine dining.\n",
      "Question   : Fishing, hunting, and birdwatching are what kind of activities that are provided in North Carolina?\n",
      "True Answer: recreational\n",
      "Predicted  : Sanskrit dramas\n",
      "BLEU Score : 0.0270\n",
      "Levenshtein Distance: 13\n",
      "------------------------------------------------------------\n",
      "Context    : Two days later, it was announced that Luis Enrique would return to Barcelona as head coach, after he agreed to a two-year deal. He was recommended by sporting director Andoni Zubizarreta, his former national teammate. Following Enrique's arrival, Barcelona broke their transfer record when they paid Liverpool F.C. between €81 to €94 million for striker Luis Suárez, who was serving a four-month ban from all football-related activity imposed by the FIFA Disciplinary Committee after biting Italian defender Giorgio Chiellini during his appearance for Uruguay in a World Cup group stage match.\n",
      "Question   : Who returned to Barcelona as head coach?\n",
      "True Answer: Luis Enrique\n",
      "Predicted  : San Fathi\n",
      "BLEU Score : 0.0243\n",
      "Levenshtein Distance: 11\n",
      "------------------------------------------------------------\n",
      "Context    : Hastings was entrusted with the power of peace and war. British judges and magistrates would also be sent to India to administer the legal system. The Governor General and the council would have complete legislative powers. The company was allowed to maintain its virtual monopoly over trade in exchange for the biennial sum and was obligated to export a minimum quantity of goods yearly to Britain. The costs of administration were to be met by the company. The Company initially welcomed these provisions, but the annual burden of the payment contributed to the steady decline of its finances.\n",
      "Question   : in British indian a jugde had to come from where to oversee the  legal system?\n",
      "True Answer: British\n",
      "Predicted  : near the hier\n",
      "BLEU Score : 0.0265\n",
      "Levenshtein Distance: 10\n",
      "------------------------------------------------------------\n",
      "Context    : The mid-1970s saw the introduction of dbx-encoded records, again for the audiophile niche market. These were completely incompatible with standard record playback preamplifiers, relying on the dbx compandor encoding/decoding scheme to greatly increase dynamic range (dbx encoded disks were recorded with the dynamic range compressed by a factor of two in dB: quiet sounds were meant to be played back at low gain and loud sounds were meant to be played back at high gain, via automatic gain control in the playback equipment; this reduced the effect of surface noise on quiet passages). A similar and very short-lived scheme involved using the CBS-developed \"CX\" noise reduction encoding/decoding scheme.\n",
      "Question   : What was required for quality playback of DBX recordings?\n",
      "True Answer: automatic gain control\n",
      "Predicted  : permus\n",
      "BLEU Score : 0.0034\n",
      "Levenshtein Distance: 21\n",
      "------------------------------------------------------------\n",
      "Context    : Many mechanical aids to calculation and measurement were constructed for astronomical and navigation use. The planisphere was a star chart invented by Abū Rayhān al-Bīrūnī in the early 11th century. The astrolabe was invented in the Hellenistic world in either the 1st or 2nd centuries BC and is often attributed to Hipparchus. A combination of the planisphere and dioptra, the astrolabe was effectively an analog computer capable of working out several different kinds of problems in spherical astronomy. An astrolabe incorporating a mechanical calendar computer and gear-wheels was invented by Abi Bakr of Isfahan, Persia in 1235. Abū Rayhān al-Bīrūnī invented the first mechanical geared lunisolar calendar astrolabe, an early fixed-wired knowledge processing machine with a gear train and gear-wheels, circa 1000 AD.\n",
      "Question   : Who invented the planisphere?\n",
      "True Answer: Abū Rayhān al-Bīrūnī\n",
      "Predicted  : Night Snions\n",
      "BLEU Score : 0.0146\n",
      "Levenshtein Distance: 17\n",
      "------------------------------------------------------------\n",
      "\n",
      "Test Set Average BLEU Score       : 0.0069\n",
      "Test Set Average Levenshtein Distance: 4.22\n",
      "\n",
      "Evaluating on Train Set...\n",
      "\n",
      "Context    : In the hindgut (element 16 in numbered diagram), or proctodaeum, undigested food particles are joined by uric acid to form fecal pellets. The rectum absorbs 90% of the water in these fecal pellets, and the dry pellet is then eliminated through the anus (element 17), completing the process of digestion. The uric acid is formed using hemolymph waste products diffused from the Malpighian tubules (element 20). It is then emptied directly into the alimentary canal, at the junction between the midgut and hindgut. The number of Malpighian tubules possessed by a given insect varies between species, ranging from only two tubules in some insects to over 100 tubules in others.:71–72, 78–80\n",
      "Question   : What is a proctodaeum?\n",
      "True Answer: the hindgut\n",
      "Predicted  : the hindgut\n",
      "BLEU Score : 1.0000\n",
      "Levenshtein Distance: 0\n",
      "------------------------------------------------------------\n",
      "Context    : Unicode is developed in conjunction with the International Organization for Standardization and shares the character repertoire with ISO/IEC 10646: the Universal Character Set. Unicode and ISO/IEC 10646 function equivalently as character encodings, but The Unicode Standard contains much more information for implementers, covering—in depth—topics such as bitwise encoding, collation and rendering. The Unicode Standard enumerates a multitude of character properties, including those needed for supporting bidirectional text. The two standards do use slightly different terminology.\n",
      "Question   : Who was Unicode developed in conjunction with?\n",
      "True Answer: International Organization for Standardization\n",
      "Predicted  : International Energy Agency of Peoples\n",
      "BLEU Score : 0.3189\n",
      "Levenshtein Distance: 29\n",
      "------------------------------------------------------------\n",
      "Context    : An infestation of the coconut rhinoceros beetle (CRB), Oryctes rhinoceros, was detected on Guam on September 12, 2007. CRB is not known to occur in the United States except in American Samoa. Delimiting surveys performed September 13–25, 2007 indicated that the infestation was limited to Tumon Bay and Faifai Beach, an area of approximately 900 acres (3.6 km2). Guam Department of Agriculture (GDA) placed quarantine on all properties within the Tumon area on October 5 and later expanded the quarantine to about 2,500 acres (10 km2) on October 25; approximately 0.5 miles (800 m) radius in all directions from all known locations of CRB infestation. CRB is native to Southern Asia and distributed throughout Asia and the Western Pacific including Sri Lanka, Upolu, Samoa, American Samoa, Palau, New Britain, West Irian, New Ireland, Pak Island and Manus Island (New Guinea), Fiji, Cocos (Keeling) Islands, Mauritius, and Reunion.\n",
      "Question   : What insect was detected in 2007?\n",
      "True Answer: coconut rhinoceros beetle\n",
      "Predicted  : coconut rotations\n",
      "BLEU Score : 0.3506\n",
      "Levenshtein Distance: 15\n",
      "------------------------------------------------------------\n",
      "Context    : The first BeiDou system, officially called the BeiDou Satellite Navigation Experimental System (simplified Chinese: 北斗卫星导航试验系统; traditional Chinese: 北斗衛星導航試驗系統; pinyin: Běidǒu wèixīng dǎoháng shìyàn xìtǒng) and also known as BeiDou-1, consists of three satellites and offers limited coverage and applications. It has been offering navigation services, mainly for customers in China and neighboring regions, since 2000.\n",
      "Question   : What was the first BeiDou system called?\n",
      "True Answer: the BeiDou Satellite Navigation Experimental System\n",
      "Predicted  : the BeiDingsexian movement\n",
      "BLEU Score : 0.1711\n",
      "Levenshtein Distance: 33\n",
      "------------------------------------------------------------\n",
      "Context    : Some Estonians, unwilling to side directly with the Nazis, joined the Finnish Army (which was allied with the Nazis) to fight against the Soviet Union. The Finnish Infantry Regiment 200 (Estonian: soomepoisid) was formed out of Estonian volunteers in Finland. Although many Estonians were recruited into the German armed forces (including Estonian Waffen-SS), the majority of them did so only in 1944 when the threat of a new invasion of Estonia by the Red Army had become imminent. In January 1944 Estonia was again facing the prospect of invasion from the Red Army and the last legitimate prime minister of the Republic of Estonia (according to the Constitution of the Republic of Estonia) delivered a radio address asking all able-bodied men born from 1904 through 1923 to report for military service. The call resulted in around 38,000 new enlistments and several thousand Estonians who had joined the Finnish Army came back to join the newly formed Territorial Defense Force, assigned to defend Estonia against the Soviet advance. It was hoped[by whom?] that by engaging in such a war Estonia would be able to attract Western support for Estonian independence.\n",
      "Question   : Who did some Estonians join as an alternative to the Germans?\n",
      "True Answer: the Finnish Army\n",
      "Predicted  : the Finnis Command\n",
      "BLEU Score : 0.5357\n",
      "Levenshtein Distance: 7\n",
      "------------------------------------------------------------\n",
      "\n",
      "Train Set Average BLEU Score       : 0.0105\n",
      "Train Set Average Levenshtein Distance: 0.30\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(contexts_test, questions_test, answers_test, \"Test\")\n",
    "evaluate_model(contexts_train, questions_train, answers_train, \"Train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ede285",
   "metadata": {
    "papermill": {
     "duration": 0.009288,
     "end_time": "2025-04-20T12:53:54.458506",
     "exception": false,
     "start_time": "2025-04-20T12:53:54.449218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelId": 310037,
     "modelInstanceId": 289298,
     "sourceId": 346261,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6149.668066,
   "end_time": "2025-04-20T12:53:57.833020",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-20T11:11:28.164954",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
