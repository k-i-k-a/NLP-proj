{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30920c9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T18:57:34.841998Z",
     "iopub.status.busy": "2025-04-15T18:57:34.841743Z",
     "iopub.status.idle": "2025-04-15T18:57:51.022459Z",
     "shell.execute_reply": "2025-04-15T18:57:51.021616Z"
    },
    "papermill": {
     "duration": 16.186168,
     "end_time": "2025-04-15T18:57:51.024132",
     "exception": false,
     "start_time": "2025-04-15T18:57:34.837964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 18:57:36.981730: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744743457.239053      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744743457.313754      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Concatenate\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd7024e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T18:57:51.029370Z",
     "iopub.status.busy": "2025-04-15T18:57:51.028913Z",
     "iopub.status.idle": "2025-04-15T18:57:53.180597Z",
     "shell.execute_reply": "2025-04-15T18:57:53.179234Z"
    },
    "papermill": {
     "duration": 2.155666,
     "end_time": "2025-04-15T18:57:53.182051",
     "exception": false,
     "start_time": "2025-04-15T18:57:51.026385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading SQuAD v1.1 dataset...\n",
      "Download complete!\n",
      "Data split completed.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib.request\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\"\n",
    "filename = \"train-v1.1.json\"\n",
    "\n",
    "if not os.path.exists(filename):\n",
    "    print(\"Downloading SQuAD v1.1 dataset...\")\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "    print(\"Download complete!\")\n",
    "else:\n",
    "    print(\"SQuAD dataset already downloaded.\")\n",
    "\n",
    "with open(\"train-v1.1.json\", \"r\") as f:\n",
    "    squad_data = json.load(f)\n",
    "\n",
    "context_to_qa = {}\n",
    "\n",
    "# Group one QA per unique context\n",
    "for article in squad_data['data']:\n",
    "    for paragraph in article['paragraphs']:\n",
    "        context = paragraph['context']\n",
    "        if context not in context_to_qa:\n",
    "            for qa in paragraph['qas']:\n",
    "                if qa['answers']:\n",
    "                    context_to_qa[context] = (qa['question'], f\"<{qa['answers'][0]['text']}>\")\n",
    "                    break \n",
    "\n",
    "unique_contexts = list(context_to_qa.items())\n",
    "random.shuffle(unique_contexts)\n",
    "\n",
    "sampled_contexts = unique_contexts[:20000]\n",
    "\n",
    "contexts = [c for c, _ in sampled_contexts]\n",
    "questions = [q for _, (q, _) in sampled_contexts]\n",
    "answers = [a for _, (_, a) in sampled_contexts]\n",
    "\n",
    "contexts_train, contexts_temp, questions_train, questions_temp, answers_train, answers_temp = train_test_split(\n",
    "    contexts, questions, answers, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "contexts_val, contexts_test, questions_val, questions_test, answers_val, answers_test = train_test_split(\n",
    "    contexts_temp, questions_temp, answers_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "with open(\"train_data.json\", \"w\") as f:\n",
    "    json.dump({\"contexts\": contexts_train, \"questions\": questions_train, \"answers\": answers_train}, f)\n",
    "\n",
    "# Save validation set\n",
    "with open(\"val_data.json\", \"w\") as f:\n",
    "    json.dump({\"contexts\": contexts_val, \"questions\": questions_val, \"answers\": answers_val}, f)\n",
    "\n",
    "# Save testing set\n",
    "with open(\"test_data.json\", \"w\") as f:\n",
    "    json.dump({\"contexts\": contexts_test, \"questions\": questions_test, \"answers\": answers_test}, f)\n",
    "\n",
    "print(\"Data split completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b62408cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T18:57:53.187270Z",
     "iopub.status.busy": "2025-04-15T18:57:53.186801Z",
     "iopub.status.idle": "2025-04-15T18:57:57.005647Z",
     "shell.execute_reply": "2025-04-15T18:57:57.005071Z"
    },
    "papermill": {
     "duration": 3.82287,
     "end_time": "2025-04-15T18:57:57.006949",
     "exception": false,
     "start_time": "2025-04-15T18:57:53.184079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Use char-level tokenizers\n",
    "context_tokenizer = Tokenizer(char_level=True, lower=False)\n",
    "question_tokenizer = Tokenizer(char_level=True, lower=False)\n",
    "answer_tokenizer = Tokenizer(char_level=True, lower=False, filters='')\n",
    "\n",
    "context_tokenizer.fit_on_texts(contexts_train)\n",
    "question_tokenizer.fit_on_texts(questions_train)\n",
    "answer_tokenizer.fit_on_texts(answers_train)\n",
    "\n",
    "context_sequences = context_tokenizer.texts_to_sequences(contexts_train)\n",
    "question_sequences = question_tokenizer.texts_to_sequences(questions_train)\n",
    "answer_sequences = answer_tokenizer.texts_to_sequences(answers_train)\n",
    "\n",
    "max_context_len = max([len(seq) for seq in context_sequences])\n",
    "max_question_len = max([len(seq) for seq in question_sequences])\n",
    "max_answer_len = max([len(seq) for seq in answer_sequences])\n",
    "\n",
    "context_padded = pad_sequences(context_sequences, maxlen=max_context_len, padding='post')\n",
    "question_padded = pad_sequences(question_sequences, maxlen=max_question_len, padding='post')\n",
    "answer_padded = pad_sequences(answer_sequences, maxlen=max_answer_len, padding='post')\n",
    "\n",
    "decoder_input_data = answer_padded[:, :-1]\n",
    "decoder_target_data = np.expand_dims(answer_padded[:, 1:], -1)\n",
    "\n",
    "context_sequences_val = context_tokenizer.texts_to_sequences(contexts_val)\n",
    "question_sequences_val = question_tokenizer.texts_to_sequences(questions_val)\n",
    "answer_sequences_val = answer_tokenizer.texts_to_sequences(answers_val)\n",
    "\n",
    "context_padded_val = pad_sequences(context_sequences_val, maxlen=max_context_len, padding='post')\n",
    "question_padded_val = pad_sequences(question_sequences_val, maxlen=max_question_len, padding='post')\n",
    "answer_padded_val = pad_sequences(answer_sequences_val, maxlen=max_answer_len, padding='post')\n",
    "\n",
    "decoder_input_data_val = answer_padded_val[:, :-1]\n",
    "decoder_target_data_val = np.expand_dims(answer_padded_val[:, 1:], -1)\n",
    "\n",
    "context_sequences_test = context_tokenizer.texts_to_sequences(contexts_test)\n",
    "question_sequences_test = question_tokenizer.texts_to_sequences(questions_test)\n",
    "answer_sequences_test = answer_tokenizer.texts_to_sequences(answers_test)\n",
    "\n",
    "context_padded_test = pad_sequences(context_sequences_test, maxlen=max_context_len, padding='post')\n",
    "question_padded_test = pad_sequences(question_sequences_test, maxlen=max_question_len, padding='post')\n",
    "answer_padded_test = pad_sequences(answer_sequences_test, maxlen=max_answer_len, padding='post')\n",
    "\n",
    "decoder_input_data_test = answer_padded_test[:, :-1]\n",
    "decoder_target_data_test = np.expand_dims(answer_padded_test[:, 1:], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b678e94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T18:57:57.013162Z",
     "iopub.status.busy": "2025-04-15T18:57:57.012911Z",
     "iopub.status.idle": "2025-04-15T22:17:01.799413Z",
     "shell.execute_reply": "2025-04-15T22:17:01.798750Z"
    },
    "papermill": {
     "duration": 11944.791532,
     "end_time": "2025-04-15T22:17:01.800832",
     "exception": false,
     "start_time": "2025-04-15T18:57:57.009300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model 1: learning_rate=0.001, optimizer=rmsprop, batch_size=32, dense_units=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744743478.485046      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1744743478.485771      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744743488.277861      63 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473/473 - 43s - 91ms/step - accuracy: 0.0253 - loss: 2.9803 - val_accuracy: 0.0295 - val_loss: 2.6481\n",
      "Epoch 2/10\n",
      "473/473 - 33s - 69ms/step - accuracy: 0.0333 - loss: 2.5023 - val_accuracy: 0.0353 - val_loss: 2.4683\n",
      "Epoch 3/10\n",
      "473/473 - 33s - 69ms/step - accuracy: 0.0367 - loss: 2.3829 - val_accuracy: 0.0390 - val_loss: 2.3710\n",
      "Epoch 4/10\n",
      "473/473 - 32s - 69ms/step - accuracy: 0.0390 - loss: 2.3053 - val_accuracy: 0.0403 - val_loss: 2.3120\n",
      "Epoch 5/10\n",
      "473/473 - 33s - 69ms/step - accuracy: 0.0408 - loss: 2.2463 - val_accuracy: 0.0406 - val_loss: 2.2906\n",
      "Epoch 6/10\n",
      "473/473 - 33s - 69ms/step - accuracy: 0.0425 - loss: 2.1964 - val_accuracy: 0.0445 - val_loss: 2.1952\n",
      "Epoch 7/10\n",
      "473/473 - 33s - 69ms/step - accuracy: 0.0442 - loss: 2.1501 - val_accuracy: 0.0459 - val_loss: 2.1671\n",
      "Epoch 8/10\n",
      "473/473 - 33s - 70ms/step - accuracy: 0.0455 - loss: 2.1087 - val_accuracy: 0.0475 - val_loss: 2.1247\n",
      "Epoch 9/10\n",
      "473/473 - 33s - 70ms/step - accuracy: 0.0470 - loss: 2.0704 - val_accuracy: 0.0484 - val_loss: 2.0891\n",
      "Epoch 10/10\n",
      "473/473 - 33s - 70ms/step - accuracy: 0.0482 - loss: 2.0344 - val_accuracy: 0.0498 - val_loss: 2.0587\n",
      "\n",
      "Training model 2: learning_rate=0.001, optimizer=rmsprop, batch_size=32, dense_units=195\n",
      "Epoch 1/10\n",
      "473/473 - 56s - 117ms/step - accuracy: 0.0329 - loss: 2.8735 - val_accuracy: 0.0342 - val_loss: 2.5233\n",
      "Epoch 2/10\n",
      "473/473 - 50s - 106ms/step - accuracy: 0.0372 - loss: 2.3728 - val_accuracy: 0.0385 - val_loss: 2.3507\n",
      "Epoch 3/10\n",
      "473/473 - 50s - 106ms/step - accuracy: 0.0419 - loss: 2.2203 - val_accuracy: 0.0431 - val_loss: 2.2400\n",
      "Epoch 4/10\n",
      "473/473 - 50s - 106ms/step - accuracy: 0.0461 - loss: 2.1047 - val_accuracy: 0.0489 - val_loss: 2.0936\n",
      "Epoch 5/10\n",
      "473/473 - 50s - 106ms/step - accuracy: 0.0497 - loss: 2.0049 - val_accuracy: 0.0515 - val_loss: 2.0313\n",
      "Epoch 6/10\n",
      "473/473 - 50s - 106ms/step - accuracy: 0.0526 - loss: 1.9228 - val_accuracy: 0.0540 - val_loss: 1.9726\n",
      "Epoch 7/10\n",
      "473/473 - 50s - 106ms/step - accuracy: 0.0551 - loss: 1.8516 - val_accuracy: 0.0566 - val_loss: 1.8981\n",
      "Epoch 8/10\n",
      "473/473 - 50s - 106ms/step - accuracy: 0.0572 - loss: 1.7882 - val_accuracy: 0.0587 - val_loss: 1.8423\n",
      "Epoch 9/10\n",
      "473/473 - 50s - 106ms/step - accuracy: 0.0589 - loss: 1.7344 - val_accuracy: 0.0587 - val_loss: 1.8426\n",
      "Epoch 10/10\n",
      "473/473 - 50s - 106ms/step - accuracy: 0.0605 - loss: 1.6869 - val_accuracy: 0.0600 - val_loss: 1.8090\n",
      "\n",
      "Training model 3: learning_rate=0.001, optimizer=rmsprop, batch_size=64, dense_units=97\n",
      "Epoch 1/10\n",
      "237/237 - 28s - 117ms/step - accuracy: 0.0283 - loss: 3.1999 - val_accuracy: 0.0261 - val_loss: 2.8379\n",
      "Epoch 2/10\n",
      "237/237 - 22s - 93ms/step - accuracy: 0.0299 - loss: 2.6273 - val_accuracy: 0.0320 - val_loss: 2.5860\n",
      "Epoch 3/10\n",
      "237/237 - 22s - 93ms/step - accuracy: 0.0335 - loss: 2.4913 - val_accuracy: 0.0340 - val_loss: 2.4891\n",
      "Epoch 4/10\n",
      "237/237 - 22s - 93ms/step - accuracy: 0.0359 - loss: 2.4092 - val_accuracy: 0.0373 - val_loss: 2.4362\n",
      "Epoch 5/10\n",
      "237/237 - 22s - 93ms/step - accuracy: 0.0377 - loss: 2.3490 - val_accuracy: 0.0377 - val_loss: 2.3864\n",
      "Epoch 6/10\n",
      "237/237 - 22s - 93ms/step - accuracy: 0.0391 - loss: 2.2997 - val_accuracy: 0.0403 - val_loss: 2.3233\n",
      "Epoch 7/10\n",
      "237/237 - 22s - 94ms/step - accuracy: 0.0404 - loss: 2.2600 - val_accuracy: 0.0397 - val_loss: 2.3115\n",
      "Epoch 8/10\n",
      "237/237 - 22s - 94ms/step - accuracy: 0.0415 - loss: 2.2243 - val_accuracy: 0.0428 - val_loss: 2.2547\n",
      "Epoch 9/10\n",
      "237/237 - 22s - 94ms/step - accuracy: 0.0425 - loss: 2.1944 - val_accuracy: 0.0428 - val_loss: 2.2517\n",
      "Epoch 10/10\n",
      "237/237 - 22s - 93ms/step - accuracy: 0.0434 - loss: 2.1664 - val_accuracy: 0.0441 - val_loss: 2.2058\n",
      "\n",
      "Training model 4: learning_rate=0.001, optimizer=rmsprop, batch_size=64, dense_units=195\n",
      "Epoch 1/10\n",
      "237/237 - 45s - 191ms/step - accuracy: 0.0500 - loss: 3.1344 - val_accuracy: 0.0309 - val_loss: 2.6941\n",
      "Epoch 2/10\n",
      "237/237 - 40s - 170ms/step - accuracy: 0.0324 - loss: 2.5310 - val_accuracy: 0.0341 - val_loss: 2.5077\n",
      "Epoch 3/10\n",
      "237/237 - 40s - 169ms/step - accuracy: 0.0366 - loss: 2.3838 - val_accuracy: 0.0384 - val_loss: 2.3811\n",
      "Epoch 4/10\n",
      "237/237 - 40s - 169ms/step - accuracy: 0.0398 - loss: 2.2829 - val_accuracy: 0.0349 - val_loss: 2.4581\n",
      "Epoch 5/10\n",
      "237/237 - 40s - 170ms/step - accuracy: 0.0425 - loss: 2.2015 - val_accuracy: 0.0439 - val_loss: 2.2250\n",
      "Epoch 6/10\n",
      "237/237 - 40s - 170ms/step - accuracy: 0.0450 - loss: 2.1296 - val_accuracy: 0.0448 - val_loss: 2.1892\n",
      "Epoch 7/10\n",
      "237/237 - 40s - 170ms/step - accuracy: 0.0475 - loss: 2.0627 - val_accuracy: 0.0481 - val_loss: 2.1195\n",
      "Epoch 8/10\n",
      "237/237 - 40s - 170ms/step - accuracy: 0.0497 - loss: 2.0021 - val_accuracy: 0.0507 - val_loss: 2.0539\n",
      "Epoch 9/10\n",
      "237/237 - 40s - 170ms/step - accuracy: 0.0516 - loss: 1.9465 - val_accuracy: 0.0526 - val_loss: 2.0005\n",
      "Epoch 10/10\n",
      "237/237 - 40s - 170ms/step - accuracy: 0.0534 - loss: 1.8973 - val_accuracy: 0.0533 - val_loss: 1.9909\n",
      "\n",
      "Training model 5: learning_rate=0.001, optimizer=rmsprop, batch_size=128, dense_units=97\n",
      "Epoch 1/10\n",
      "119/119 - 23s - 192ms/step - accuracy: 0.0144 - loss: 3.4794 - val_accuracy: 0.0242 - val_loss: 3.1884\n",
      "Epoch 2/10\n",
      "119/119 - 17s - 144ms/step - accuracy: 0.0241 - loss: 2.9334 - val_accuracy: 0.0293 - val_loss: 2.7703\n",
      "Epoch 3/10\n",
      "119/119 - 17s - 144ms/step - accuracy: 0.0295 - loss: 2.6673 - val_accuracy: 0.0282 - val_loss: 2.6828\n",
      "Epoch 4/10\n",
      "119/119 - 17s - 145ms/step - accuracy: 0.0316 - loss: 2.5627 - val_accuracy: 0.0330 - val_loss: 2.5676\n",
      "Epoch 5/10\n",
      "119/119 - 17s - 145ms/step - accuracy: 0.0332 - loss: 2.4993 - val_accuracy: 0.0334 - val_loss: 2.5440\n",
      "Epoch 6/10\n",
      "119/119 - 17s - 145ms/step - accuracy: 0.0347 - loss: 2.4522 - val_accuracy: 0.0343 - val_loss: 2.4916\n",
      "Epoch 7/10\n",
      "119/119 - 17s - 145ms/step - accuracy: 0.0356 - loss: 2.4162 - val_accuracy: 0.0354 - val_loss: 2.4939\n",
      "Epoch 8/10\n",
      "119/119 - 17s - 145ms/step - accuracy: 0.0365 - loss: 2.3836 - val_accuracy: 0.0363 - val_loss: 2.4486\n",
      "Epoch 9/10\n",
      "119/119 - 17s - 145ms/step - accuracy: 0.0373 - loss: 2.3544 - val_accuracy: 0.0372 - val_loss: 2.4021\n",
      "Epoch 10/10\n",
      "119/119 - 17s - 145ms/step - accuracy: 0.0382 - loss: 2.3262 - val_accuracy: 0.0385 - val_loss: 2.3684\n",
      "\n",
      "Training model 6: learning_rate=0.001, optimizer=rmsprop, batch_size=128, dense_units=195\n",
      "Epoch 1/10\n",
      "119/119 - 40s - 332ms/step - accuracy: 0.0245 - loss: 3.4274 - val_accuracy: 0.0131 - val_loss: 3.1890\n",
      "Epoch 2/10\n",
      "119/119 - 34s - 290ms/step - accuracy: 0.0254 - loss: 2.8264 - val_accuracy: 0.0274 - val_loss: 2.7409\n",
      "Epoch 3/10\n",
      "119/119 - 35s - 290ms/step - accuracy: 0.0312 - loss: 2.5690 - val_accuracy: 0.0325 - val_loss: 2.5672\n",
      "Epoch 4/10\n",
      "119/119 - 35s - 296ms/step - accuracy: 0.0343 - loss: 2.4549 - val_accuracy: 0.0332 - val_loss: 2.5540\n",
      "Epoch 5/10\n",
      "119/119 - 35s - 293ms/step - accuracy: 0.0366 - loss: 2.3819 - val_accuracy: 0.0363 - val_loss: 2.4565\n",
      "Epoch 6/10\n",
      "119/119 - 35s - 292ms/step - accuracy: 0.0384 - loss: 2.3208 - val_accuracy: 0.0373 - val_loss: 2.3940\n",
      "Epoch 7/10\n",
      "119/119 - 35s - 292ms/step - accuracy: 0.0401 - loss: 2.2649 - val_accuracy: 0.0401 - val_loss: 2.3167\n",
      "Epoch 8/10\n",
      "119/119 - 35s - 294ms/step - accuracy: 0.0418 - loss: 2.2138 - val_accuracy: 0.0402 - val_loss: 2.3197\n",
      "Epoch 9/10\n",
      "119/119 - 35s - 294ms/step - accuracy: 0.0432 - loss: 2.1714 - val_accuracy: 0.0426 - val_loss: 2.3001\n",
      "Epoch 10/10\n",
      "119/119 - 35s - 293ms/step - accuracy: 0.0447 - loss: 2.1309 - val_accuracy: 0.0442 - val_loss: 2.2309\n",
      "\n",
      "Training model 7: learning_rate=0.001, optimizer=adam, batch_size=32, dense_units=97\n",
      "Epoch 1/10\n",
      "473/473 - 39s - 82ms/step - accuracy: 0.0286 - loss: 2.7884 - val_accuracy: 0.0364 - val_loss: 2.4684\n",
      "Epoch 2/10\n",
      "473/473 - 32s - 68ms/step - accuracy: 0.0370 - loss: 2.3842 - val_accuracy: 0.0403 - val_loss: 2.3303\n",
      "Epoch 3/10\n",
      "473/473 - 32s - 68ms/step - accuracy: 0.0404 - loss: 2.2673 - val_accuracy: 0.0432 - val_loss: 2.2414\n",
      "Epoch 4/10\n",
      "473/473 - 32s - 68ms/step - accuracy: 0.0429 - loss: 2.1883 - val_accuracy: 0.0456 - val_loss: 2.1682\n",
      "Epoch 5/10\n",
      "473/473 - 32s - 67ms/step - accuracy: 0.0455 - loss: 2.1146 - val_accuracy: 0.0481 - val_loss: 2.1094\n",
      "Epoch 6/10\n",
      "473/473 - 32s - 68ms/step - accuracy: 0.0477 - loss: 2.0539 - val_accuracy: 0.0501 - val_loss: 2.0526\n",
      "Epoch 7/10\n",
      "473/473 - 32s - 68ms/step - accuracy: 0.0496 - loss: 1.9971 - val_accuracy: 0.0521 - val_loss: 2.0109\n",
      "Epoch 8/10\n",
      "473/473 - 32s - 69ms/step - accuracy: 0.0512 - loss: 1.9513 - val_accuracy: 0.0537 - val_loss: 1.9708\n",
      "Epoch 9/10\n",
      "473/473 - 33s - 69ms/step - accuracy: 0.0526 - loss: 1.9098 - val_accuracy: 0.0543 - val_loss: 1.9424\n",
      "Epoch 10/10\n",
      "473/473 - 33s - 70ms/step - accuracy: 0.0538 - loss: 1.8719 - val_accuracy: 0.0556 - val_loss: 1.9158\n",
      "\n",
      "Training model 8: learning_rate=0.001, optimizer=adam, batch_size=32, dense_units=195\n",
      "Epoch 1/10\n",
      "473/473 - 56s - 118ms/step - accuracy: 0.0311 - loss: 2.6548 - val_accuracy: 0.0393 - val_loss: 2.3698\n",
      "Epoch 2/10\n",
      "473/473 - 49s - 103ms/step - accuracy: 0.0410 - loss: 2.2590 - val_accuracy: 0.0446 - val_loss: 2.1871\n",
      "Epoch 3/10\n",
      "473/473 - 49s - 104ms/step - accuracy: 0.0463 - loss: 2.0952 - val_accuracy: 0.0505 - val_loss: 2.0469\n",
      "Epoch 4/10\n",
      "473/473 - 49s - 104ms/step - accuracy: 0.0513 - loss: 1.9591 - val_accuracy: 0.0551 - val_loss: 1.9258\n",
      "Epoch 5/10\n",
      "473/473 - 49s - 104ms/step - accuracy: 0.0549 - loss: 1.8456 - val_accuracy: 0.0583 - val_loss: 1.8470\n",
      "Epoch 6/10\n",
      "473/473 - 49s - 104ms/step - accuracy: 0.0577 - loss: 1.7537 - val_accuracy: 0.0599 - val_loss: 1.7883\n",
      "Epoch 7/10\n",
      "473/473 - 49s - 103ms/step - accuracy: 0.0602 - loss: 1.6830 - val_accuracy: 0.0617 - val_loss: 1.7433\n",
      "Epoch 8/10\n",
      "473/473 - 49s - 103ms/step - accuracy: 0.0620 - loss: 1.6253 - val_accuracy: 0.0630 - val_loss: 1.7088\n",
      "Epoch 9/10\n",
      "473/473 - 49s - 104ms/step - accuracy: 0.0635 - loss: 1.5702 - val_accuracy: 0.0633 - val_loss: 1.6989\n",
      "Epoch 10/10\n",
      "473/473 - 49s - 103ms/step - accuracy: 0.0649 - loss: 1.5262 - val_accuracy: 0.0643 - val_loss: 1.6745\n",
      "\n",
      "Training model 9: learning_rate=0.001, optimizer=adam, batch_size=64, dense_units=97\n",
      "Epoch 1/10\n",
      "237/237 - 28s - 117ms/step - accuracy: 0.0232 - loss: 3.0422 - val_accuracy: 0.0323 - val_loss: 2.5897\n",
      "Epoch 2/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0335 - loss: 2.4908 - val_accuracy: 0.0366 - val_loss: 2.4348\n",
      "Epoch 3/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0371 - loss: 2.3732 - val_accuracy: 0.0395 - val_loss: 2.3477\n",
      "Epoch 4/10\n",
      "237/237 - 21s - 89ms/step - accuracy: 0.0392 - loss: 2.3009 - val_accuracy: 0.0414 - val_loss: 2.2908\n",
      "Epoch 5/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0409 - loss: 2.2469 - val_accuracy: 0.0431 - val_loss: 2.2332\n",
      "Epoch 6/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0424 - loss: 2.1990 - val_accuracy: 0.0447 - val_loss: 2.1994\n",
      "Epoch 7/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0439 - loss: 2.1589 - val_accuracy: 0.0459 - val_loss: 2.1639\n",
      "Epoch 8/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0452 - loss: 2.1199 - val_accuracy: 0.0466 - val_loss: 2.1409\n",
      "Epoch 9/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0464 - loss: 2.0825 - val_accuracy: 0.0485 - val_loss: 2.0913\n",
      "Epoch 10/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0476 - loss: 2.0475 - val_accuracy: 0.0496 - val_loss: 2.0654\n",
      "\n",
      "Training model 10: learning_rate=0.001, optimizer=adam, batch_size=64, dense_units=195\n",
      "Epoch 1/10\n",
      "237/237 - 45s - 192ms/step - accuracy: 0.0272 - loss: 2.8348 - val_accuracy: 0.0348 - val_loss: 2.4841\n",
      "Epoch 2/10\n",
      "237/237 - 39s - 164ms/step - accuracy: 0.0376 - loss: 2.3706 - val_accuracy: 0.0409 - val_loss: 2.3130\n",
      "Epoch 3/10\n",
      "237/237 - 39s - 163ms/step - accuracy: 0.0417 - loss: 2.2360 - val_accuracy: 0.0447 - val_loss: 2.1901\n",
      "Epoch 4/10\n",
      "237/237 - 39s - 164ms/step - accuracy: 0.0450 - loss: 2.1304 - val_accuracy: 0.0481 - val_loss: 2.1085\n",
      "Epoch 5/10\n",
      "237/237 - 39s - 164ms/step - accuracy: 0.0482 - loss: 2.0436 - val_accuracy: 0.0513 - val_loss: 2.0318\n",
      "Epoch 6/10\n",
      "237/237 - 39s - 163ms/step - accuracy: 0.0511 - loss: 1.9597 - val_accuracy: 0.0535 - val_loss: 1.9641\n",
      "Epoch 7/10\n",
      "237/237 - 39s - 164ms/step - accuracy: 0.0534 - loss: 1.8881 - val_accuracy: 0.0555 - val_loss: 1.9073\n",
      "Epoch 8/10\n",
      "237/237 - 39s - 164ms/step - accuracy: 0.0555 - loss: 1.8221 - val_accuracy: 0.0574 - val_loss: 1.8547\n",
      "Epoch 9/10\n",
      "237/237 - 39s - 163ms/step - accuracy: 0.0573 - loss: 1.7696 - val_accuracy: 0.0589 - val_loss: 1.8117\n",
      "Epoch 10/10\n",
      "237/237 - 39s - 164ms/step - accuracy: 0.0587 - loss: 1.7213 - val_accuracy: 0.0599 - val_loss: 1.7885\n",
      "\n",
      "Training model 11: learning_rate=0.001, optimizer=adam, batch_size=128, dense_units=97\n",
      "Epoch 1/10\n",
      "119/119 - 23s - 191ms/step - accuracy: 0.0186 - loss: 3.3297 - val_accuracy: 0.0286 - val_loss: 2.7951\n",
      "Epoch 2/10\n",
      "119/119 - 16s - 137ms/step - accuracy: 0.0298 - loss: 2.6424 - val_accuracy: 0.0329 - val_loss: 2.5650\n",
      "Epoch 3/10\n",
      "119/119 - 16s - 137ms/step - accuracy: 0.0333 - loss: 2.4950 - val_accuracy: 0.0354 - val_loss: 2.4721\n",
      "Epoch 4/10\n",
      "119/119 - 16s - 138ms/step - accuracy: 0.0359 - loss: 2.4155 - val_accuracy: 0.0381 - val_loss: 2.4037\n",
      "Epoch 5/10\n",
      "119/119 - 16s - 137ms/step - accuracy: 0.0377 - loss: 2.3608 - val_accuracy: 0.0391 - val_loss: 2.3583\n",
      "Epoch 6/10\n",
      "119/119 - 16s - 138ms/step - accuracy: 0.0389 - loss: 2.3168 - val_accuracy: 0.0410 - val_loss: 2.3110\n",
      "Epoch 7/10\n",
      "119/119 - 16s - 138ms/step - accuracy: 0.0400 - loss: 2.2780 - val_accuracy: 0.0415 - val_loss: 2.2792\n",
      "Epoch 8/10\n",
      "119/119 - 16s - 137ms/step - accuracy: 0.0410 - loss: 2.2430 - val_accuracy: 0.0427 - val_loss: 2.2480\n",
      "Epoch 9/10\n",
      "119/119 - 16s - 137ms/step - accuracy: 0.0418 - loss: 2.2141 - val_accuracy: 0.0437 - val_loss: 2.2204\n",
      "Epoch 10/10\n",
      "119/119 - 16s - 138ms/step - accuracy: 0.0429 - loss: 2.1858 - val_accuracy: 0.0446 - val_loss: 2.1934\n",
      "\n",
      "Training model 12: learning_rate=0.001, optimizer=adam, batch_size=128, dense_units=195\n",
      "Epoch 1/10\n",
      "119/119 - 40s - 336ms/step - accuracy: 0.0227 - loss: 3.0896 - val_accuracy: 0.0321 - val_loss: 2.6090\n",
      "Epoch 2/10\n",
      "119/119 - 34s - 283ms/step - accuracy: 0.0334 - loss: 2.4966 - val_accuracy: 0.0374 - val_loss: 2.4292\n",
      "Epoch 3/10\n",
      "119/119 - 34s - 282ms/step - accuracy: 0.0377 - loss: 2.3636 - val_accuracy: 0.0404 - val_loss: 2.3388\n",
      "Epoch 4/10\n",
      "119/119 - 34s - 283ms/step - accuracy: 0.0403 - loss: 2.2770 - val_accuracy: 0.0426 - val_loss: 2.2569\n",
      "Epoch 5/10\n",
      "119/119 - 34s - 284ms/step - accuracy: 0.0424 - loss: 2.2044 - val_accuracy: 0.0441 - val_loss: 2.2020\n",
      "Epoch 6/10\n",
      "119/119 - 34s - 285ms/step - accuracy: 0.0442 - loss: 2.1462 - val_accuracy: 0.0461 - val_loss: 2.1435\n",
      "Epoch 7/10\n",
      "119/119 - 34s - 284ms/step - accuracy: 0.0462 - loss: 2.0924 - val_accuracy: 0.0480 - val_loss: 2.1013\n",
      "Epoch 8/10\n",
      "119/119 - 34s - 283ms/step - accuracy: 0.0478 - loss: 2.0458 - val_accuracy: 0.0498 - val_loss: 2.0575\n",
      "Epoch 9/10\n",
      "119/119 - 34s - 285ms/step - accuracy: 0.0496 - loss: 1.9961 - val_accuracy: 0.0510 - val_loss: 2.0193\n",
      "Epoch 10/10\n",
      "119/119 - 34s - 284ms/step - accuracy: 0.0510 - loss: 1.9580 - val_accuracy: 0.0531 - val_loss: 1.9818\n",
      "\n",
      "Training model 13: learning_rate=0.0005, optimizer=rmsprop, batch_size=32, dense_units=97\n",
      "Epoch 1/10\n",
      "473/473 - 40s - 84ms/step - accuracy: 0.0180 - loss: 3.2714 - val_accuracy: 0.0276 - val_loss: 2.8478\n",
      "Epoch 2/10\n",
      "473/473 - 33s - 70ms/step - accuracy: 0.0292 - loss: 2.6995 - val_accuracy: 0.0318 - val_loss: 2.6165\n",
      "Epoch 3/10\n",
      "473/473 - 33s - 70ms/step - accuracy: 0.0321 - loss: 2.5499 - val_accuracy: 0.0332 - val_loss: 2.5700\n",
      "Epoch 4/10\n",
      "473/473 - 34s - 71ms/step - accuracy: 0.0343 - loss: 2.4691 - val_accuracy: 0.0359 - val_loss: 2.4650\n",
      "Epoch 5/10\n",
      "473/473 - 34s - 71ms/step - accuracy: 0.0358 - loss: 2.4067 - val_accuracy: 0.0380 - val_loss: 2.3978\n",
      "Epoch 6/10\n",
      "473/473 - 33s - 70ms/step - accuracy: 0.0372 - loss: 2.3580 - val_accuracy: 0.0380 - val_loss: 2.3805\n",
      "Epoch 7/10\n",
      "473/473 - 33s - 71ms/step - accuracy: 0.0385 - loss: 2.3210 - val_accuracy: 0.0392 - val_loss: 2.3441\n",
      "Epoch 8/10\n",
      "473/473 - 33s - 71ms/step - accuracy: 0.0395 - loss: 2.2883 - val_accuracy: 0.0404 - val_loss: 2.3053\n",
      "Epoch 9/10\n",
      "473/473 - 34s - 71ms/step - accuracy: 0.0405 - loss: 2.2598 - val_accuracy: 0.0418 - val_loss: 2.2799\n",
      "Epoch 10/10\n",
      "473/473 - 33s - 70ms/step - accuracy: 0.0413 - loss: 2.2338 - val_accuracy: 0.0427 - val_loss: 2.2512\n",
      "\n",
      "Training model 14: learning_rate=0.0005, optimizer=rmsprop, batch_size=32, dense_units=195\n",
      "Epoch 1/10\n",
      "473/473 - 56s - 118ms/step - accuracy: 0.0460 - loss: 3.1094 - val_accuracy: 0.0282 - val_loss: 2.7453\n",
      "Epoch 2/10\n",
      "473/473 - 50s - 105ms/step - accuracy: 0.0319 - loss: 2.5538 - val_accuracy: 0.0335 - val_loss: 2.5135\n",
      "Epoch 3/10\n",
      "473/473 - 50s - 105ms/step - accuracy: 0.0360 - loss: 2.4080 - val_accuracy: 0.0381 - val_loss: 2.3876\n",
      "Epoch 4/10\n",
      "473/473 - 50s - 105ms/step - accuracy: 0.0387 - loss: 2.3219 - val_accuracy: 0.0396 - val_loss: 2.3423\n",
      "Epoch 5/10\n",
      "473/473 - 50s - 105ms/step - accuracy: 0.0407 - loss: 2.2564 - val_accuracy: 0.0421 - val_loss: 2.2795\n",
      "Epoch 6/10\n",
      "473/473 - 50s - 105ms/step - accuracy: 0.0426 - loss: 2.1996 - val_accuracy: 0.0438 - val_loss: 2.2135\n",
      "Epoch 7/10\n",
      "473/473 - 50s - 105ms/step - accuracy: 0.0441 - loss: 2.1498 - val_accuracy: 0.0445 - val_loss: 2.1913\n",
      "Epoch 8/10\n",
      "473/473 - 50s - 105ms/step - accuracy: 0.0459 - loss: 2.1023 - val_accuracy: 0.0475 - val_loss: 2.1205\n",
      "Epoch 9/10\n",
      "473/473 - 49s - 104ms/step - accuracy: 0.0475 - loss: 2.0591 - val_accuracy: 0.0487 - val_loss: 2.1185\n",
      "Epoch 10/10\n",
      "473/473 - 50s - 105ms/step - accuracy: 0.0489 - loss: 2.0199 - val_accuracy: 0.0505 - val_loss: 2.0539\n",
      "\n",
      "Training model 15: learning_rate=0.0005, optimizer=rmsprop, batch_size=64, dense_units=97\n",
      "Epoch 1/10\n",
      "237/237 - 28s - 119ms/step - accuracy: 0.0189 - loss: 3.4910 - val_accuracy: 0.0220 - val_loss: 3.1617\n",
      "Epoch 2/10\n",
      "237/237 - 22s - 94ms/step - accuracy: 0.0252 - loss: 2.9177 - val_accuracy: 0.0284 - val_loss: 2.7896\n",
      "Epoch 3/10\n",
      "237/237 - 22s - 93ms/step - accuracy: 0.0295 - loss: 2.6561 - val_accuracy: 0.0300 - val_loss: 2.6374\n",
      "Epoch 4/10\n",
      "237/237 - 22s - 93ms/step - accuracy: 0.0315 - loss: 2.5573 - val_accuracy: 0.0332 - val_loss: 2.5652\n",
      "Epoch 5/10\n",
      "237/237 - 22s - 93ms/step - accuracy: 0.0332 - loss: 2.4972 - val_accuracy: 0.0345 - val_loss: 2.5003\n",
      "Epoch 6/10\n",
      "237/237 - 22s - 93ms/step - accuracy: 0.0345 - loss: 2.4505 - val_accuracy: 0.0362 - val_loss: 2.4555\n",
      "Epoch 7/10\n",
      "237/237 - 22s - 93ms/step - accuracy: 0.0355 - loss: 2.4128 - val_accuracy: 0.0370 - val_loss: 2.4202\n",
      "Epoch 8/10\n",
      "237/237 - 22s - 94ms/step - accuracy: 0.0366 - loss: 2.3816 - val_accuracy: 0.0357 - val_loss: 2.4330\n",
      "Epoch 9/10\n",
      "237/237 - 22s - 93ms/step - accuracy: 0.0374 - loss: 2.3549 - val_accuracy: 0.0382 - val_loss: 2.3778\n",
      "Epoch 10/10\n",
      "237/237 - 22s - 94ms/step - accuracy: 0.0380 - loss: 2.3321 - val_accuracy: 0.0380 - val_loss: 2.3695\n",
      "\n",
      "Training model 16: learning_rate=0.0005, optimizer=rmsprop, batch_size=64, dense_units=195\n",
      "Epoch 1/10\n",
      "237/237 - 46s - 195ms/step - accuracy: 0.0338 - loss: 3.3433 - val_accuracy: 0.0250 - val_loss: 2.9558\n",
      "Epoch 2/10\n",
      "237/237 - 40s - 169ms/step - accuracy: 0.0281 - loss: 2.7194 - val_accuracy: 0.0306 - val_loss: 2.6620\n",
      "Epoch 3/10\n",
      "237/237 - 40s - 169ms/step - accuracy: 0.0324 - loss: 2.5379 - val_accuracy: 0.0340 - val_loss: 2.5390\n",
      "Epoch 4/10\n",
      "237/237 - 40s - 170ms/step - accuracy: 0.0351 - loss: 2.4423 - val_accuracy: 0.0335 - val_loss: 2.4967\n",
      "Epoch 5/10\n",
      "237/237 - 40s - 170ms/step - accuracy: 0.0370 - loss: 2.3778 - val_accuracy: 0.0374 - val_loss: 2.4211\n",
      "Epoch 6/10\n",
      "237/237 - 40s - 170ms/step - accuracy: 0.0386 - loss: 2.3264 - val_accuracy: 0.0393 - val_loss: 2.3723\n",
      "Epoch 7/10\n",
      "237/237 - 40s - 170ms/step - accuracy: 0.0400 - loss: 2.2809 - val_accuracy: 0.0408 - val_loss: 2.3244\n",
      "Epoch 8/10\n",
      "237/237 - 40s - 169ms/step - accuracy: 0.0412 - loss: 2.2405 - val_accuracy: 0.0412 - val_loss: 2.2950\n",
      "Epoch 9/10\n",
      "237/237 - 40s - 170ms/step - accuracy: 0.0425 - loss: 2.2023 - val_accuracy: 0.0429 - val_loss: 2.2411\n",
      "Epoch 10/10\n",
      "237/237 - 40s - 170ms/step - accuracy: 0.0436 - loss: 2.1670 - val_accuracy: 0.0431 - val_loss: 2.2318\n",
      "\n",
      "Training model 17: learning_rate=0.0005, optimizer=rmsprop, batch_size=128, dense_units=97\n",
      "Epoch 1/10\n",
      "119/119 - 23s - 190ms/step - accuracy: 0.0111 - loss: 3.6842 - val_accuracy: 0.0134 - val_loss: 3.3747\n",
      "Epoch 2/10\n",
      "119/119 - 17s - 145ms/step - accuracy: 0.0156 - loss: 3.2861 - val_accuracy: 0.0197 - val_loss: 3.1787\n",
      "Epoch 3/10\n",
      "119/119 - 17s - 145ms/step - accuracy: 0.0223 - loss: 3.0574 - val_accuracy: 0.0246 - val_loss: 2.9688\n",
      "Epoch 4/10\n",
      "119/119 - 17s - 145ms/step - accuracy: 0.0266 - loss: 2.8293 - val_accuracy: 0.0279 - val_loss: 2.8067\n",
      "Epoch 5/10\n",
      "119/119 - 17s - 144ms/step - accuracy: 0.0283 - loss: 2.7008 - val_accuracy: 0.0292 - val_loss: 2.6911\n",
      "Epoch 6/10\n",
      "119/119 - 17s - 144ms/step - accuracy: 0.0299 - loss: 2.6351 - val_accuracy: 0.0307 - val_loss: 2.6509\n",
      "Epoch 7/10\n",
      "119/119 - 17s - 144ms/step - accuracy: 0.0311 - loss: 2.5901 - val_accuracy: 0.0321 - val_loss: 2.6040\n",
      "Epoch 8/10\n",
      "119/119 - 17s - 144ms/step - accuracy: 0.0320 - loss: 2.5477 - val_accuracy: 0.0328 - val_loss: 2.5857\n",
      "Epoch 9/10\n",
      "119/119 - 17s - 144ms/step - accuracy: 0.0328 - loss: 2.5133 - val_accuracy: 0.0332 - val_loss: 2.5354\n",
      "Epoch 10/10\n",
      "119/119 - 17s - 144ms/step - accuracy: 0.0339 - loss: 2.4811 - val_accuracy: 0.0337 - val_loss: 2.5228\n",
      "\n",
      "Training model 18: learning_rate=0.0005, optimizer=rmsprop, batch_size=128, dense_units=195\n",
      "Epoch 1/10\n",
      "119/119 - 42s - 350ms/step - accuracy: 0.0188 - loss: 3.5800 - val_accuracy: 0.0130 - val_loss: 3.3431\n",
      "Epoch 2/10\n",
      "119/119 - 35s - 298ms/step - accuracy: 0.0349 - loss: 3.1396 - val_accuracy: 0.0235 - val_loss: 2.9770\n",
      "Epoch 3/10\n",
      "119/119 - 35s - 297ms/step - accuracy: 0.0262 - loss: 2.8213 - val_accuracy: 0.0254 - val_loss: 2.8247\n",
      "Epoch 4/10\n",
      "119/119 - 36s - 298ms/step - accuracy: 0.0292 - loss: 2.6691 - val_accuracy: 0.0310 - val_loss: 2.6502\n",
      "Epoch 5/10\n",
      "119/119 - 35s - 298ms/step - accuracy: 0.0311 - loss: 2.5760 - val_accuracy: 0.0282 - val_loss: 2.6831\n",
      "Epoch 6/10\n",
      "119/119 - 35s - 298ms/step - accuracy: 0.0330 - loss: 2.5105 - val_accuracy: 0.0326 - val_loss: 2.5589\n",
      "Epoch 7/10\n",
      "119/119 - 36s - 298ms/step - accuracy: 0.0344 - loss: 2.4589 - val_accuracy: 0.0342 - val_loss: 2.5042\n",
      "Epoch 8/10\n",
      "119/119 - 36s - 299ms/step - accuracy: 0.0357 - loss: 2.4178 - val_accuracy: 0.0361 - val_loss: 2.4462\n",
      "Epoch 9/10\n",
      "119/119 - 35s - 297ms/step - accuracy: 0.0367 - loss: 2.3842 - val_accuracy: 0.0378 - val_loss: 2.4259\n",
      "Epoch 10/10\n",
      "119/119 - 36s - 299ms/step - accuracy: 0.0375 - loss: 2.3552 - val_accuracy: 0.0367 - val_loss: 2.4290\n",
      "\n",
      "Training model 19: learning_rate=0.0005, optimizer=adam, batch_size=32, dense_units=97\n",
      "Epoch 1/10\n",
      "473/473 - 40s - 85ms/step - accuracy: 0.0235 - loss: 3.0262 - val_accuracy: 0.0312 - val_loss: 2.5999\n",
      "Epoch 2/10\n",
      "473/473 - 33s - 69ms/step - accuracy: 0.0329 - loss: 2.5083 - val_accuracy: 0.0358 - val_loss: 2.4637\n",
      "Epoch 3/10\n",
      "473/473 - 33s - 70ms/step - accuracy: 0.0362 - loss: 2.4060 - val_accuracy: 0.0383 - val_loss: 2.3858\n",
      "Epoch 4/10\n",
      "473/473 - 33s - 70ms/step - accuracy: 0.0384 - loss: 2.3321 - val_accuracy: 0.0406 - val_loss: 2.3173\n",
      "Epoch 5/10\n",
      "473/473 - 33s - 70ms/step - accuracy: 0.0400 - loss: 2.2759 - val_accuracy: 0.0419 - val_loss: 2.2713\n",
      "Epoch 6/10\n",
      "473/473 - 33s - 70ms/step - accuracy: 0.0414 - loss: 2.2312 - val_accuracy: 0.0435 - val_loss: 2.2322\n",
      "Epoch 7/10\n",
      "473/473 - 33s - 69ms/step - accuracy: 0.0427 - loss: 2.1919 - val_accuracy: 0.0447 - val_loss: 2.1956\n",
      "Epoch 8/10\n",
      "473/473 - 33s - 69ms/step - accuracy: 0.0440 - loss: 2.1536 - val_accuracy: 0.0459 - val_loss: 2.1639\n",
      "Epoch 9/10\n",
      "473/473 - 33s - 69ms/step - accuracy: 0.0452 - loss: 2.1186 - val_accuracy: 0.0469 - val_loss: 2.1306\n",
      "Epoch 10/10\n",
      "473/473 - 33s - 69ms/step - accuracy: 0.0463 - loss: 2.0866 - val_accuracy: 0.0476 - val_loss: 2.1096\n",
      "\n",
      "Training model 20: learning_rate=0.0005, optimizer=adam, batch_size=32, dense_units=195\n",
      "Epoch 1/10\n",
      "473/473 - 55s - 117ms/step - accuracy: 0.0272 - loss: 2.8424 - val_accuracy: 0.0340 - val_loss: 2.5228\n",
      "Epoch 2/10\n",
      "473/473 - 49s - 103ms/step - accuracy: 0.0364 - loss: 2.4084 - val_accuracy: 0.0396 - val_loss: 2.3557\n",
      "Epoch 3/10\n",
      "473/473 - 49s - 103ms/step - accuracy: 0.0400 - loss: 2.2837 - val_accuracy: 0.0433 - val_loss: 2.2463\n",
      "Epoch 4/10\n",
      "473/473 - 49s - 103ms/step - accuracy: 0.0429 - loss: 2.1902 - val_accuracy: 0.0458 - val_loss: 2.1676\n",
      "Epoch 5/10\n",
      "473/473 - 49s - 103ms/step - accuracy: 0.0456 - loss: 2.1115 - val_accuracy: 0.0484 - val_loss: 2.0999\n",
      "Epoch 6/10\n",
      "473/473 - 49s - 103ms/step - accuracy: 0.0480 - loss: 2.0440 - val_accuracy: 0.0509 - val_loss: 2.0430\n",
      "Epoch 7/10\n",
      "473/473 - 49s - 103ms/step - accuracy: 0.0504 - loss: 1.9824 - val_accuracy: 0.0527 - val_loss: 1.9903\n",
      "Epoch 8/10\n",
      "473/473 - 48s - 103ms/step - accuracy: 0.0525 - loss: 1.9215 - val_accuracy: 0.0547 - val_loss: 1.9394\n",
      "Epoch 9/10\n",
      "473/473 - 49s - 103ms/step - accuracy: 0.0542 - loss: 1.8684 - val_accuracy: 0.0560 - val_loss: 1.9001\n",
      "Epoch 10/10\n",
      "473/473 - 48s - 102ms/step - accuracy: 0.0558 - loss: 1.8221 - val_accuracy: 0.0578 - val_loss: 1.8569\n",
      "\n",
      "Training model 21: learning_rate=0.0005, optimizer=adam, batch_size=64, dense_units=97\n",
      "Epoch 1/10\n",
      "237/237 - 28s - 118ms/step - accuracy: 0.0190 - loss: 3.2923 - val_accuracy: 0.0302 - val_loss: 2.7470\n",
      "Epoch 2/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0307 - loss: 2.6120 - val_accuracy: 0.0335 - val_loss: 2.5470\n",
      "Epoch 3/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0332 - loss: 2.4901 - val_accuracy: 0.0353 - val_loss: 2.4713\n",
      "Epoch 4/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0353 - loss: 2.4225 - val_accuracy: 0.0376 - val_loss: 2.4077\n",
      "Epoch 5/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0371 - loss: 2.3706 - val_accuracy: 0.0393 - val_loss: 2.3630\n",
      "Epoch 6/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0386 - loss: 2.3263 - val_accuracy: 0.0407 - val_loss: 2.3215\n",
      "Epoch 7/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0398 - loss: 2.2878 - val_accuracy: 0.0418 - val_loss: 2.2854\n",
      "Epoch 8/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0408 - loss: 2.2533 - val_accuracy: 0.0426 - val_loss: 2.2587\n",
      "Epoch 9/10\n",
      "237/237 - 21s - 89ms/step - accuracy: 0.0416 - loss: 2.2249 - val_accuracy: 0.0433 - val_loss: 2.2333\n",
      "Epoch 10/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0425 - loss: 2.1979 - val_accuracy: 0.0440 - val_loss: 2.2100\n",
      "\n",
      "Training model 22: learning_rate=0.0005, optimizer=adam, batch_size=64, dense_units=195\n",
      "Epoch 1/10\n",
      "237/237 - 45s - 188ms/step - accuracy: 0.0235 - loss: 3.0373 - val_accuracy: 0.0327 - val_loss: 2.5848\n",
      "Epoch 2/10\n",
      "237/237 - 39s - 163ms/step - accuracy: 0.0339 - loss: 2.4837 - val_accuracy: 0.0376 - val_loss: 2.4265\n",
      "Epoch 3/10\n",
      "237/237 - 38s - 162ms/step - accuracy: 0.0374 - loss: 2.3691 - val_accuracy: 0.0398 - val_loss: 2.3393\n",
      "Epoch 4/10\n",
      "237/237 - 39s - 163ms/step - accuracy: 0.0398 - loss: 2.2885 - val_accuracy: 0.0422 - val_loss: 2.2677\n",
      "Epoch 5/10\n",
      "237/237 - 39s - 163ms/step - accuracy: 0.0417 - loss: 2.2223 - val_accuracy: 0.0441 - val_loss: 2.2106\n",
      "Epoch 6/10\n",
      "237/237 - 39s - 163ms/step - accuracy: 0.0435 - loss: 2.1699 - val_accuracy: 0.0457 - val_loss: 2.1681\n",
      "Epoch 7/10\n",
      "237/237 - 39s - 163ms/step - accuracy: 0.0452 - loss: 2.1202 - val_accuracy: 0.0476 - val_loss: 2.1195\n",
      "Epoch 8/10\n",
      "237/237 - 39s - 163ms/step - accuracy: 0.0469 - loss: 2.0745 - val_accuracy: 0.0491 - val_loss: 2.0741\n",
      "Epoch 9/10\n",
      "237/237 - 39s - 163ms/step - accuracy: 0.0486 - loss: 2.0284 - val_accuracy: 0.0507 - val_loss: 2.0370\n",
      "Epoch 10/10\n",
      "237/237 - 39s - 163ms/step - accuracy: 0.0501 - loss: 1.9837 - val_accuracy: 0.0523 - val_loss: 1.9983\n",
      "\n",
      "Training model 23: learning_rate=0.0005, optimizer=adam, batch_size=128, dense_units=97\n",
      "Epoch 1/10\n",
      "119/119 - 23s - 194ms/step - accuracy: 0.0151 - loss: 3.6121 - val_accuracy: 0.0211 - val_loss: 3.0991\n",
      "Epoch 2/10\n",
      "119/119 - 17s - 140ms/step - accuracy: 0.0267 - loss: 2.8537 - val_accuracy: 0.0313 - val_loss: 2.6716\n",
      "Epoch 3/10\n",
      "119/119 - 16s - 138ms/step - accuracy: 0.0310 - loss: 2.5955 - val_accuracy: 0.0330 - val_loss: 2.5601\n",
      "Epoch 4/10\n",
      "119/119 - 16s - 137ms/step - accuracy: 0.0329 - loss: 2.5095 - val_accuracy: 0.0349 - val_loss: 2.4914\n",
      "Epoch 5/10\n",
      "119/119 - 16s - 137ms/step - accuracy: 0.0347 - loss: 2.4498 - val_accuracy: 0.0367 - val_loss: 2.4417\n",
      "Epoch 6/10\n",
      "119/119 - 16s - 137ms/step - accuracy: 0.0362 - loss: 2.4074 - val_accuracy: 0.0381 - val_loss: 2.4035\n",
      "Epoch 7/10\n",
      "119/119 - 16s - 138ms/step - accuracy: 0.0373 - loss: 2.3700 - val_accuracy: 0.0387 - val_loss: 2.3708\n",
      "Epoch 8/10\n",
      "119/119 - 16s - 138ms/step - accuracy: 0.0382 - loss: 2.3396 - val_accuracy: 0.0397 - val_loss: 2.3393\n",
      "Epoch 9/10\n",
      "119/119 - 16s - 138ms/step - accuracy: 0.0392 - loss: 2.3084 - val_accuracy: 0.0407 - val_loss: 2.3106\n",
      "Epoch 10/10\n",
      "119/119 - 16s - 138ms/step - accuracy: 0.0400 - loss: 2.2805 - val_accuracy: 0.0413 - val_loss: 2.2865\n",
      "\n",
      "Training model 24: learning_rate=0.0005, optimizer=adam, batch_size=128, dense_units=195\n",
      "Epoch 1/10\n",
      "119/119 - 40s - 334ms/step - accuracy: 0.0182 - loss: 3.3555 - val_accuracy: 0.0286 - val_loss: 2.8024\n",
      "Epoch 2/10\n",
      "119/119 - 34s - 286ms/step - accuracy: 0.0303 - loss: 2.6247 - val_accuracy: 0.0333 - val_loss: 2.5411\n",
      "Epoch 3/10\n",
      "119/119 - 34s - 289ms/step - accuracy: 0.0342 - loss: 2.4739 - val_accuracy: 0.0362 - val_loss: 2.4572\n",
      "Epoch 4/10\n",
      "119/119 - 34s - 286ms/step - accuracy: 0.0366 - loss: 2.3978 - val_accuracy: 0.0390 - val_loss: 2.3817\n",
      "Epoch 5/10\n",
      "119/119 - 34s - 286ms/step - accuracy: 0.0386 - loss: 2.3365 - val_accuracy: 0.0408 - val_loss: 2.3232\n",
      "Epoch 6/10\n",
      "119/119 - 34s - 284ms/step - accuracy: 0.0401 - loss: 2.2820 - val_accuracy: 0.0424 - val_loss: 2.2736\n",
      "Epoch 7/10\n",
      "119/119 - 34s - 286ms/step - accuracy: 0.0416 - loss: 2.2358 - val_accuracy: 0.0430 - val_loss: 2.2411\n",
      "Epoch 8/10\n",
      "119/119 - 34s - 284ms/step - accuracy: 0.0428 - loss: 2.1950 - val_accuracy: 0.0449 - val_loss: 2.1953\n",
      "Epoch 9/10\n",
      "119/119 - 34s - 285ms/step - accuracy: 0.0441 - loss: 2.1577 - val_accuracy: 0.0460 - val_loss: 2.1614\n",
      "Epoch 10/10\n",
      "119/119 - 34s - 286ms/step - accuracy: 0.0453 - loss: 2.1231 - val_accuracy: 0.0472 - val_loss: 2.1308\n",
      "\n",
      "Training model 25: learning_rate=0.0001, optimizer=rmsprop, batch_size=32, dense_units=97\n",
      "Epoch 1/10\n",
      "473/473 - 40s - 84ms/step - accuracy: 0.0111 - loss: 3.8904 - val_accuracy: 0.0129 - val_loss: 3.3763\n",
      "Epoch 2/10\n",
      "473/473 - 34s - 71ms/step - accuracy: 0.0145 - loss: 3.3503 - val_accuracy: 0.0216 - val_loss: 3.2928\n",
      "Epoch 3/10\n",
      "473/473 - 34s - 71ms/step - accuracy: 0.2146 - loss: 3.1968 - val_accuracy: 0.0265 - val_loss: 3.1315\n",
      "Epoch 4/10\n",
      "473/473 - 34s - 71ms/step - accuracy: 0.0227 - loss: 3.0521 - val_accuracy: 0.0259 - val_loss: 2.9689\n",
      "Epoch 5/10\n",
      "473/473 - 34s - 71ms/step - accuracy: 0.0264 - loss: 2.8627 - val_accuracy: 0.0286 - val_loss: 2.7954\n",
      "Epoch 6/10\n",
      "473/473 - 34s - 71ms/step - accuracy: 0.0283 - loss: 2.7324 - val_accuracy: 0.0300 - val_loss: 2.7074\n",
      "Epoch 7/10\n",
      "473/473 - 34s - 71ms/step - accuracy: 0.0295 - loss: 2.6665 - val_accuracy: 0.0311 - val_loss: 2.6567\n",
      "Epoch 8/10\n",
      "473/473 - 33s - 71ms/step - accuracy: 0.0301 - loss: 2.6254 - val_accuracy: 0.0313 - val_loss: 2.6259\n",
      "Epoch 9/10\n",
      "473/473 - 34s - 71ms/step - accuracy: 0.0306 - loss: 2.5951 - val_accuracy: 0.0320 - val_loss: 2.5981\n",
      "Epoch 10/10\n",
      "473/473 - 34s - 71ms/step - accuracy: 0.0313 - loss: 2.5711 - val_accuracy: 0.0328 - val_loss: 2.5796\n",
      "\n",
      "Training model 26: learning_rate=0.0001, optimizer=rmsprop, batch_size=32, dense_units=195\n",
      "Epoch 1/10\n",
      "473/473 - 57s - 120ms/step - accuracy: 0.0117 - loss: 3.6743 - val_accuracy: 0.0147 - val_loss: 3.3529\n",
      "Epoch 2/10\n",
      "473/473 - 50s - 105ms/step - accuracy: 0.0756 - loss: 3.2382 - val_accuracy: 0.0328 - val_loss: 3.1163\n",
      "Epoch 3/10\n",
      "473/473 - 50s - 106ms/step - accuracy: 0.0320 - loss: 2.9716 - val_accuracy: 0.0277 - val_loss: 2.8526\n",
      "Epoch 4/10\n",
      "473/473 - 50s - 105ms/step - accuracy: 0.0285 - loss: 2.7470 - val_accuracy: 0.0298 - val_loss: 2.7005\n",
      "Epoch 5/10\n",
      "473/473 - 50s - 105ms/step - accuracy: 0.0300 - loss: 2.6398 - val_accuracy: 0.0315 - val_loss: 2.6347\n",
      "Epoch 6/10\n",
      "473/473 - 50s - 105ms/step - accuracy: 0.0310 - loss: 2.5799 - val_accuracy: 0.0310 - val_loss: 2.5971\n",
      "Epoch 7/10\n",
      "473/473 - 50s - 106ms/step - accuracy: 0.0318 - loss: 2.5371 - val_accuracy: 0.0340 - val_loss: 2.5337\n",
      "Epoch 8/10\n",
      "473/473 - 50s - 106ms/step - accuracy: 0.0331 - loss: 2.5020 - val_accuracy: 0.0333 - val_loss: 2.5250\n",
      "Epoch 9/10\n",
      "473/473 - 50s - 106ms/step - accuracy: 0.0344 - loss: 2.4723 - val_accuracy: 0.0357 - val_loss: 2.4770\n",
      "Epoch 10/10\n",
      "473/473 - 50s - 105ms/step - accuracy: 0.0351 - loss: 2.4468 - val_accuracy: 0.0357 - val_loss: 2.4654\n",
      "\n",
      "Training model 27: learning_rate=0.0001, optimizer=rmsprop, batch_size=64, dense_units=97\n",
      "Epoch 1/10\n",
      "237/237 - 29s - 120ms/step - accuracy: 0.0093 - loss: 4.3203 - val_accuracy: 0.0131 - val_loss: 3.4388\n",
      "Epoch 2/10\n",
      "237/237 - 22s - 94ms/step - accuracy: 0.0122 - loss: 3.3881 - val_accuracy: 0.0130 - val_loss: 3.3592\n",
      "Epoch 3/10\n",
      "237/237 - 22s - 93ms/step - accuracy: 0.0662 - loss: 3.3416 - val_accuracy: 0.0165 - val_loss: 3.3143\n",
      "Epoch 4/10\n",
      "237/237 - 22s - 93ms/step - accuracy: 0.8824 - loss: 3.2615 - val_accuracy: 0.8948 - val_loss: 3.2086\n",
      "Epoch 5/10\n",
      "237/237 - 22s - 93ms/step - accuracy: 0.5548 - loss: 3.1634 - val_accuracy: 0.0229 - val_loss: 3.1369\n",
      "Epoch 6/10\n",
      "237/237 - 22s - 93ms/step - accuracy: 0.0201 - loss: 3.0942 - val_accuracy: 0.0235 - val_loss: 3.0587\n",
      "Epoch 7/10\n",
      "237/237 - 22s - 93ms/step - accuracy: 0.0245 - loss: 2.9906 - val_accuracy: 0.0270 - val_loss: 2.9361\n",
      "Epoch 8/10\n",
      "237/237 - 22s - 93ms/step - accuracy: 0.0264 - loss: 2.8702 - val_accuracy: 0.0279 - val_loss: 2.8281\n",
      "Epoch 9/10\n",
      "237/237 - 22s - 93ms/step - accuracy: 0.0273 - loss: 2.7825 - val_accuracy: 0.0288 - val_loss: 2.7583\n",
      "Epoch 10/10\n",
      "237/237 - 22s - 93ms/step - accuracy: 0.0280 - loss: 2.7227 - val_accuracy: 0.0295 - val_loss: 2.7141\n",
      "\n",
      "Training model 28: learning_rate=0.0001, optimizer=rmsprop, batch_size=64, dense_units=195\n",
      "Epoch 1/10\n",
      "237/237 - 47s - 197ms/step - accuracy: 0.0114 - loss: 4.0183 - val_accuracy: 0.0134 - val_loss: 3.3694\n",
      "Epoch 2/10\n",
      "237/237 - 40s - 169ms/step - accuracy: 0.0130 - loss: 3.3452 - val_accuracy: 0.0135 - val_loss: 3.3176\n",
      "Epoch 3/10\n",
      "237/237 - 40s - 169ms/step - accuracy: 0.0418 - loss: 3.2301 - val_accuracy: 0.1650 - val_loss: 3.1823\n",
      "Epoch 4/10\n",
      "237/237 - 40s - 170ms/step - accuracy: 0.0313 - loss: 3.0907 - val_accuracy: 0.0278 - val_loss: 3.0379\n",
      "Epoch 5/10\n",
      "237/237 - 40s - 169ms/step - accuracy: 0.0260 - loss: 2.9421 - val_accuracy: 0.0286 - val_loss: 2.8663\n",
      "Epoch 6/10\n",
      "237/237 - 40s - 169ms/step - accuracy: 0.0279 - loss: 2.7934 - val_accuracy: 0.0282 - val_loss: 2.7954\n",
      "Epoch 7/10\n",
      "237/237 - 40s - 169ms/step - accuracy: 0.0288 - loss: 2.7062 - val_accuracy: 0.0292 - val_loss: 2.7022\n",
      "Epoch 8/10\n",
      "237/237 - 40s - 170ms/step - accuracy: 0.0296 - loss: 2.6543 - val_accuracy: 0.0305 - val_loss: 2.6605\n",
      "Epoch 9/10\n",
      "237/237 - 40s - 169ms/step - accuracy: 0.0304 - loss: 2.6170 - val_accuracy: 0.0319 - val_loss: 2.6226\n",
      "Epoch 10/10\n",
      "237/237 - 40s - 170ms/step - accuracy: 0.0310 - loss: 2.5877 - val_accuracy: 0.0319 - val_loss: 2.5916\n",
      "\n",
      "Training model 29: learning_rate=0.0001, optimizer=rmsprop, batch_size=128, dense_units=97\n",
      "Epoch 1/10\n",
      "119/119 - 24s - 198ms/step - accuracy: 0.0108 - loss: 4.9679 - val_accuracy: 0.0121 - val_loss: 3.9509\n",
      "Epoch 2/10\n",
      "119/119 - 17s - 147ms/step - accuracy: 0.0117 - loss: 3.5812 - val_accuracy: 0.0131 - val_loss: 3.4277\n",
      "Epoch 3/10\n",
      "119/119 - 17s - 145ms/step - accuracy: 0.0122 - loss: 3.3972 - val_accuracy: 0.0131 - val_loss: 3.3741\n",
      "Epoch 4/10\n",
      "119/119 - 17s - 144ms/step - accuracy: 0.0122 - loss: 3.3692 - val_accuracy: 0.0131 - val_loss: 3.3614\n",
      "Epoch 5/10\n",
      "119/119 - 17s - 144ms/step - accuracy: 0.0125 - loss: 3.3584 - val_accuracy: 0.0134 - val_loss: 3.3512\n",
      "Epoch 6/10\n",
      "119/119 - 17s - 144ms/step - accuracy: 0.0126 - loss: 3.3483 - val_accuracy: 0.0135 - val_loss: 3.3418\n",
      "Epoch 7/10\n",
      "119/119 - 17s - 145ms/step - accuracy: 0.0126 - loss: 3.3322 - val_accuracy: 0.0135 - val_loss: 3.3205\n",
      "Epoch 8/10\n",
      "119/119 - 17s - 145ms/step - accuracy: 0.1208 - loss: 3.2978 - val_accuracy: 0.8912 - val_loss: 3.2698\n",
      "Epoch 9/10\n",
      "119/119 - 17s - 145ms/step - accuracy: 0.8958 - loss: 3.2258 - val_accuracy: 0.8494 - val_loss: 3.1893\n",
      "Epoch 10/10\n",
      "119/119 - 17s - 145ms/step - accuracy: 0.9006 - loss: 3.1420 - val_accuracy: 0.8986 - val_loss: 3.1071\n",
      "\n",
      "Training model 30: learning_rate=0.0001, optimizer=rmsprop, batch_size=128, dense_units=195\n",
      "Epoch 1/10\n",
      "119/119 - 42s - 349ms/step - accuracy: 0.0085 - loss: 4.5231 - val_accuracy: 0.0124 - val_loss: 3.4752\n",
      "Epoch 2/10\n",
      "119/119 - 35s - 294ms/step - accuracy: 0.0123 - loss: 3.4026 - val_accuracy: 0.0124 - val_loss: 3.3818\n",
      "Epoch 3/10\n",
      "119/119 - 35s - 292ms/step - accuracy: 0.0125 - loss: 3.3554 - val_accuracy: 0.0133 - val_loss: 3.3502\n",
      "Epoch 4/10\n",
      "119/119 - 35s - 293ms/step - accuracy: 0.0126 - loss: 3.3344 - val_accuracy: 0.0183 - val_loss: 3.3295\n",
      "Epoch 5/10\n",
      "119/119 - 35s - 294ms/step - accuracy: 0.0181 - loss: 3.2884 - val_accuracy: 0.0228 - val_loss: 3.2510\n",
      "Epoch 6/10\n",
      "119/119 - 35s - 294ms/step - accuracy: 0.0642 - loss: 3.1912 - val_accuracy: 0.0314 - val_loss: 3.1550\n",
      "Epoch 7/10\n",
      "119/119 - 35s - 293ms/step - accuracy: 0.0290 - loss: 3.1147 - val_accuracy: 0.0327 - val_loss: 3.1096\n",
      "Epoch 8/10\n",
      "119/119 - 35s - 293ms/step - accuracy: 0.0294 - loss: 3.0415 - val_accuracy: 0.0297 - val_loss: 3.0141\n",
      "Epoch 9/10\n",
      "119/119 - 35s - 293ms/step - accuracy: 0.0281 - loss: 2.9434 - val_accuracy: 0.0281 - val_loss: 2.9236\n",
      "Epoch 10/10\n",
      "119/119 - 35s - 294ms/step - accuracy: 0.0267 - loss: 2.8535 - val_accuracy: 0.0273 - val_loss: 2.8381\n",
      "\n",
      "Training model 31: learning_rate=0.0001, optimizer=adam, batch_size=32, dense_units=97\n",
      "Epoch 1/10\n",
      "473/473 - 40s - 85ms/step - accuracy: 0.0143 - loss: 3.6048 - val_accuracy: 0.0187 - val_loss: 3.1806\n",
      "Epoch 2/10\n",
      "473/473 - 33s - 69ms/step - accuracy: 0.0235 - loss: 3.0159 - val_accuracy: 0.0286 - val_loss: 2.8386\n",
      "Epoch 3/10\n",
      "473/473 - 33s - 69ms/step - accuracy: 0.0289 - loss: 2.7243 - val_accuracy: 0.0315 - val_loss: 2.6556\n",
      "Epoch 4/10\n",
      "473/473 - 33s - 69ms/step - accuracy: 0.0311 - loss: 2.6053 - val_accuracy: 0.0328 - val_loss: 2.5817\n",
      "Epoch 5/10\n",
      "473/473 - 33s - 69ms/step - accuracy: 0.0322 - loss: 2.5456 - val_accuracy: 0.0340 - val_loss: 2.5349\n",
      "Epoch 6/10\n",
      "473/473 - 33s - 69ms/step - accuracy: 0.0332 - loss: 2.5022 - val_accuracy: 0.0350 - val_loss: 2.5047\n",
      "Epoch 7/10\n",
      "473/473 - 33s - 70ms/step - accuracy: 0.0342 - loss: 2.4714 - val_accuracy: 0.0360 - val_loss: 2.4736\n",
      "Epoch 8/10\n",
      "473/473 - 33s - 69ms/step - accuracy: 0.0350 - loss: 2.4435 - val_accuracy: 0.0365 - val_loss: 2.4473\n",
      "Epoch 9/10\n",
      "473/473 - 33s - 69ms/step - accuracy: 0.0359 - loss: 2.4192 - val_accuracy: 0.0375 - val_loss: 2.4241\n",
      "Epoch 10/10\n",
      "473/473 - 33s - 69ms/step - accuracy: 0.0367 - loss: 2.3975 - val_accuracy: 0.0379 - val_loss: 2.4059\n",
      "\n",
      "Training model 32: learning_rate=0.0001, optimizer=adam, batch_size=32, dense_units=195\n",
      "Epoch 1/10\n",
      "473/473 - 56s - 118ms/step - accuracy: 0.0181 - loss: 3.3814 - val_accuracy: 0.0285 - val_loss: 2.9153\n",
      "Epoch 2/10\n",
      "473/473 - 49s - 103ms/step - accuracy: 0.0292 - loss: 2.7187 - val_accuracy: 0.0314 - val_loss: 2.6267\n",
      "Epoch 3/10\n",
      "473/473 - 49s - 103ms/step - accuracy: 0.0318 - loss: 2.5574 - val_accuracy: 0.0347 - val_loss: 2.5325\n",
      "Epoch 4/10\n",
      "473/473 - 49s - 103ms/step - accuracy: 0.0338 - loss: 2.4844 - val_accuracy: 0.0361 - val_loss: 2.4704\n",
      "Epoch 5/10\n",
      "473/473 - 49s - 103ms/step - accuracy: 0.0355 - loss: 2.4349 - val_accuracy: 0.0378 - val_loss: 2.4283\n",
      "Epoch 6/10\n",
      "473/473 - 49s - 103ms/step - accuracy: 0.0368 - loss: 2.3926 - val_accuracy: 0.0388 - val_loss: 2.3917\n",
      "Epoch 7/10\n",
      "473/473 - 49s - 103ms/step - accuracy: 0.0379 - loss: 2.3588 - val_accuracy: 0.0397 - val_loss: 2.3585\n",
      "Epoch 8/10\n",
      "473/473 - 49s - 103ms/step - accuracy: 0.0389 - loss: 2.3267 - val_accuracy: 0.0405 - val_loss: 2.3310\n",
      "Epoch 9/10\n",
      "473/473 - 48s - 103ms/step - accuracy: 0.0397 - loss: 2.2988 - val_accuracy: 0.0416 - val_loss: 2.3005\n",
      "Epoch 10/10\n",
      "473/473 - 49s - 103ms/step - accuracy: 0.0405 - loss: 2.2727 - val_accuracy: 0.0423 - val_loss: 2.2849\n",
      "\n",
      "Training model 33: learning_rate=0.0001, optimizer=adam, batch_size=64, dense_units=97\n",
      "Epoch 1/10\n",
      "237/237 - 28s - 118ms/step - accuracy: 0.0115 - loss: 3.9167 - val_accuracy: 0.0133 - val_loss: 3.3566\n",
      "Epoch 2/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0180 - loss: 3.2422 - val_accuracy: 0.0191 - val_loss: 3.1580\n",
      "Epoch 3/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0207 - loss: 3.0899 - val_accuracy: 0.0244 - val_loss: 3.0102\n",
      "Epoch 4/10\n",
      "237/237 - 21s - 89ms/step - accuracy: 0.0269 - loss: 2.8788 - val_accuracy: 0.0291 - val_loss: 2.7758\n",
      "Epoch 5/10\n",
      "237/237 - 21s - 89ms/step - accuracy: 0.0286 - loss: 2.7104 - val_accuracy: 0.0304 - val_loss: 2.6821\n",
      "Epoch 6/10\n",
      "237/237 - 22s - 91ms/step - accuracy: 0.0295 - loss: 2.6455 - val_accuracy: 0.0313 - val_loss: 2.6373\n",
      "Epoch 7/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0304 - loss: 2.6056 - val_accuracy: 0.0323 - val_loss: 2.6009\n",
      "Epoch 8/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0313 - loss: 2.5722 - val_accuracy: 0.0329 - val_loss: 2.5704\n",
      "Epoch 9/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0320 - loss: 2.5416 - val_accuracy: 0.0334 - val_loss: 2.5448\n",
      "Epoch 10/10\n",
      "237/237 - 21s - 90ms/step - accuracy: 0.0325 - loss: 2.5153 - val_accuracy: 0.0344 - val_loss: 2.5171\n",
      "\n",
      "Training model 34: learning_rate=0.0001, optimizer=adam, batch_size=64, dense_units=195\n",
      "Epoch 1/10\n",
      "237/237 - 45s - 192ms/step - accuracy: 0.0368 - loss: 3.6550 - val_accuracy: 0.0188 - val_loss: 3.1782\n",
      "Epoch 2/10\n",
      "237/237 - 38s - 162ms/step - accuracy: 0.0223 - loss: 3.0457 - val_accuracy: 0.0288 - val_loss: 2.8646\n",
      "Epoch 3/10\n",
      "237/237 - 39s - 162ms/step - accuracy: 0.0293 - loss: 2.7154 - val_accuracy: 0.0315 - val_loss: 2.6420\n",
      "Epoch 4/10\n",
      "237/237 - 39s - 163ms/step - accuracy: 0.0310 - loss: 2.5891 - val_accuracy: 0.0330 - val_loss: 2.5733\n",
      "Epoch 5/10\n",
      "237/237 - 39s - 163ms/step - accuracy: 0.0324 - loss: 2.5334 - val_accuracy: 0.0339 - val_loss: 2.5333\n",
      "Epoch 6/10\n",
      "237/237 - 39s - 163ms/step - accuracy: 0.0335 - loss: 2.4935 - val_accuracy: 0.0351 - val_loss: 2.4933\n",
      "Epoch 7/10\n",
      "237/237 - 39s - 162ms/step - accuracy: 0.0346 - loss: 2.4602 - val_accuracy: 0.0362 - val_loss: 2.4649\n",
      "Epoch 8/10\n",
      "237/237 - 39s - 163ms/step - accuracy: 0.0356 - loss: 2.4312 - val_accuracy: 0.0376 - val_loss: 2.4349\n",
      "Epoch 9/10\n",
      "237/237 - 39s - 163ms/step - accuracy: 0.0364 - loss: 2.4053 - val_accuracy: 0.0379 - val_loss: 2.4109\n",
      "Epoch 10/10\n",
      "237/237 - 39s - 163ms/step - accuracy: 0.0372 - loss: 2.3807 - val_accuracy: 0.0388 - val_loss: 2.3873\n",
      "\n",
      "Training model 35: learning_rate=0.0001, optimizer=adam, batch_size=128, dense_units=97\n",
      "Epoch 1/10\n",
      "119/119 - 23s - 194ms/step - accuracy: 0.0099 - loss: 4.3836 - val_accuracy: 0.0129 - val_loss: 3.4615\n",
      "Epoch 2/10\n",
      "119/119 - 17s - 139ms/step - accuracy: 0.0128 - loss: 3.3915 - val_accuracy: 0.0183 - val_loss: 3.3311\n",
      "Epoch 3/10\n",
      "119/119 - 16s - 138ms/step - accuracy: 0.0177 - loss: 3.2592 - val_accuracy: 0.0203 - val_loss: 3.1901\n",
      "Epoch 4/10\n",
      "119/119 - 16s - 137ms/step - accuracy: 0.0199 - loss: 3.1384 - val_accuracy: 0.0230 - val_loss: 3.0835\n",
      "Epoch 5/10\n",
      "119/119 - 16s - 137ms/step - accuracy: 0.0254 - loss: 3.0071 - val_accuracy: 0.0282 - val_loss: 2.9298\n",
      "Epoch 6/10\n",
      "119/119 - 16s - 137ms/step - accuracy: 0.0276 - loss: 2.8617 - val_accuracy: 0.0289 - val_loss: 2.8059\n",
      "Epoch 7/10\n",
      "119/119 - 16s - 137ms/step - accuracy: 0.0284 - loss: 2.7592 - val_accuracy: 0.0300 - val_loss: 2.7274\n",
      "Epoch 8/10\n",
      "119/119 - 16s - 138ms/step - accuracy: 0.0292 - loss: 2.6932 - val_accuracy: 0.0308 - val_loss: 2.6789\n",
      "Epoch 9/10\n",
      "119/119 - 16s - 138ms/step - accuracy: 0.0301 - loss: 2.6495 - val_accuracy: 0.0317 - val_loss: 2.6436\n",
      "Epoch 10/10\n",
      "119/119 - 16s - 138ms/step - accuracy: 0.0306 - loss: 2.6177 - val_accuracy: 0.0319 - val_loss: 2.6152\n",
      "\n",
      "Training model 36: learning_rate=0.0001, optimizer=adam, batch_size=128, dense_units=195\n",
      "Epoch 1/10\n",
      "119/119 - 40s - 334ms/step - accuracy: 0.0117 - loss: 4.0039 - val_accuracy: 0.0187 - val_loss: 3.3504\n",
      "Epoch 2/10\n",
      "119/119 - 34s - 282ms/step - accuracy: 0.0183 - loss: 3.2310 - val_accuracy: 0.0213 - val_loss: 3.1301\n",
      "Epoch 3/10\n",
      "119/119 - 34s - 282ms/step - accuracy: 0.0237 - loss: 3.0232 - val_accuracy: 0.0281 - val_loss: 2.9112\n",
      "Epoch 4/10\n",
      "119/119 - 34s - 284ms/step - accuracy: 0.0281 - loss: 2.8050 - val_accuracy: 0.0300 - val_loss: 2.7369\n",
      "Epoch 5/10\n",
      "119/119 - 34s - 283ms/step - accuracy: 0.0295 - loss: 2.6766 - val_accuracy: 0.0315 - val_loss: 2.6446\n",
      "Epoch 6/10\n",
      "119/119 - 34s - 283ms/step - accuracy: 0.0309 - loss: 2.6058 - val_accuracy: 0.0326 - val_loss: 2.5917\n",
      "Epoch 7/10\n",
      "119/119 - 34s - 285ms/step - accuracy: 0.0320 - loss: 2.5589 - val_accuracy: 0.0337 - val_loss: 2.5541\n",
      "Epoch 8/10\n",
      "119/119 - 34s - 283ms/step - accuracy: 0.0329 - loss: 2.5237 - val_accuracy: 0.0347 - val_loss: 2.5247\n",
      "Epoch 9/10\n",
      "119/119 - 34s - 284ms/step - accuracy: 0.0334 - loss: 2.4951 - val_accuracy: 0.0349 - val_loss: 2.4978\n",
      "Epoch 10/10\n",
      "119/119 - 34s - 283ms/step - accuracy: 0.0342 - loss: 2.4700 - val_accuracy: 0.0356 - val_loss: 2.4761\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "\n",
    "vocab_context = len(context_tokenizer.word_index) + 1\n",
    "vocab_question = len(question_tokenizer.word_index) + 1\n",
    "vocab_answer = len(answer_tokenizer.word_index) + 1\n",
    "\n",
    "learning_rates = [0.001, 0.0005, 0.0001]\n",
    "optimizers = {\n",
    "    \"rmsprop\": lambda lr: RMSprop(learning_rate=lr),\n",
    "    \"adam\": lambda lr: Adam(learning_rate=lr)\n",
    "}\n",
    "batch_sizes = [32, 64, 128]\n",
    "dense_units_list = [vocab_answer//2,vocab_answer] \n",
    "\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "os.makedirs(\"training_curves\", exist_ok=True)\n",
    "\n",
    "i = 1\n",
    "for lr in learning_rates:\n",
    "    for opt_name, opt in optimizers.items():\n",
    "        for batch_size in batch_sizes:\n",
    "            for dense_units in dense_units_list:\n",
    "                print(f\"\\nTraining model {i}: learning_rate={lr}, optimizer={opt_name}, batch_size={batch_size}, dense_units={dense_units}\")\n",
    "\n",
    "                # Encoder\n",
    "                context_input = Input(shape=(context_padded.shape[1],), name=\"context_input\")\n",
    "                question_input = Input(shape=(question_padded.shape[1],), name=\"question_input\")\n",
    "\n",
    "                context_embedding = Embedding(vocab_context, dense_units, mask_zero=True)(context_input)\n",
    "                question_embedding = Embedding(vocab_question, dense_units, mask_zero=True)(question_input)\n",
    "\n",
    "                context_lstm = LSTM(dense_units, return_state=True, dropout=0.3)\n",
    "                _, context_h, context_c = context_lstm(context_embedding)\n",
    "\n",
    "                question_lstm = LSTM(dense_units, return_state=True, dropout=0.3)\n",
    "                _, question_h, question_c = question_lstm(question_embedding)\n",
    "\n",
    "                state_h = Concatenate()([context_h, question_h])\n",
    "                state_c = Concatenate()([context_c, question_c])\n",
    "                encoder_states = [state_h, state_c]\n",
    "\n",
    "                # Decoder\n",
    "                decoder_input = Input(shape=(None,), name=\"decoder_input\")\n",
    "                decoder_embedding_layer = Embedding(vocab_answer, dense_units, mask_zero=True)\n",
    "                decoder_embedding = decoder_embedding_layer(decoder_input)\n",
    "\n",
    "                decoder_lstm = LSTM(dense_units * 2, return_sequences=True, return_state=True, dropout=0.3)\n",
    "                decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "                decoder_dense_hidden = Dense(dense_units, activation='relu')(decoder_outputs)\n",
    "                decoder_dense_output = Dense(vocab_answer, activation='softmax')(decoder_dense_hidden)\n",
    "\n",
    "                model = Model([context_input, question_input, decoder_input], decoder_dense_output)\n",
    "                model.compile(optimizer=opt(lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "                history = model.fit(\n",
    "                    [context_padded, question_padded, decoder_input_data],\n",
    "                    decoder_target_data,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=10,\n",
    "                    validation_data=([context_padded_val, question_padded_val, decoder_input_data_val], decoder_target_data_val),\n",
    "                    verbose=2\n",
    "                )\n",
    "\n",
    "                model_name = f\"model_lr{lr}_opt{opt_name}_bs{batch_size}_du{dense_units}\"\n",
    "                model_path = f\"saved_models/{model_name}\"\n",
    "\n",
    "                # Save encoder inference model\n",
    "                encoder_model = Model([context_input, question_input], encoder_states)\n",
    "                encoder_model.save(f\"{model_path}_encoder.h5\")\n",
    "\n",
    "                # Save decoder inference model\n",
    "                decoder_state_input_h = Input(shape=(dense_units * 2,))\n",
    "                decoder_state_input_c = Input(shape=(dense_units * 2,))\n",
    "                decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "                decoder_inputs_inf = Input(shape=(1,))\n",
    "                decoder_embedded_inf = decoder_embedding_layer(decoder_inputs_inf)\n",
    "\n",
    "                decoder_outputs_inf, state_h_inf, state_c_inf = decoder_lstm(\n",
    "                    decoder_embedded_inf, initial_state=decoder_states_inputs)\n",
    "\n",
    "                decoder_dense_hidden_inf = Dense(dense_units, activation='relu')(decoder_outputs_inf)\n",
    "                decoder_outputs_final = Dense(vocab_answer, activation='softmax')(decoder_dense_hidden_inf)\n",
    "\n",
    "                decoder_model = Model(\n",
    "                    [decoder_inputs_inf, decoder_state_input_h, decoder_state_input_c],\n",
    "                    [decoder_outputs_final, state_h_inf, state_c_inf]\n",
    "                )\n",
    "\n",
    "                decoder_model.save(f\"{model_path}_decoder.h5\")\n",
    "\n",
    "                # Plot training & validation loss and accuracy\n",
    "                graph_path = f\"training_curves/loss_accuracy_curve_{model_name}.png\"\n",
    "                plt.figure(figsize=(12, 6))\n",
    "\n",
    "                # Loss Plot\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.plot(history.history['loss'], label='Training Loss')\n",
    "                plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "                plt.title(f\"Loss Curve ({model_name})\")\n",
    "                plt.xlabel('Epochs')\n",
    "                plt.ylabel('Loss')\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "\n",
    "                # Accuracy Plot\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "                plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "                plt.title(f\"Accuracy Curve ({model_name})\")\n",
    "                plt.xlabel('Epochs')\n",
    "                plt.ylabel('Accuracy')\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(graph_path)\n",
    "                plt.close()\n",
    "\n",
    "                i += 1\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11975.091028,
   "end_time": "2025-04-15T22:17:05.292391",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-15T18:57:30.201363",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
